{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Kitsune's documentation!","text":"<p>Kitsune is the platform that powers SuMo support.mozilla.org. It is a web application based on Django, a Python web application framework.</p>"},{"location":"advanced-search/","title":"Advanced search","text":""},{"location":"advanced-search/#advanced-search","title":"Advanced Search","text":"<pre><code>.. contents:: :local:\n</code></pre> <p>Kitsune supports an advanced search syntax in all its search boxes.</p> <p>A number of search operators and tokens, described below, take a <code>{field_name}</code> as an argument. The valid field names for each of our document types are explained in the Document Fields section.</p> <p>The most basic search token is simply an individual word. For example, the query <code>firefox crashes</code> contains two tokens <code>firefox</code> and <code>crashes</code>.</p> <p>By default all simple tokens specified must exist in the same field in a document for it to be matched. So our <code>firefox crashes</code> query will only match a document with both <code>firefox</code> and <code>crashes</code> in the same field. This behaviour can be modified using the operators below.</p>"},{"location":"advanced-search/#quoted-phrase","title":"Quoted Phrase","text":"<p><code>\"x y z\"</code></p> <p>Matches the phrase, disabling synonym matching.</p> <p>e.g. <code>\"firefox accounts\"</code> will match \"firefox accounts\" but not \"firefox can't find my account\".</p> <p>e.g. <code>add-ons NOT \"themes\"</code> will match add-ons and extensions, but not themes.</p>"},{"location":"advanced-search/#field-operator","title":"Field Operator","text":"<p><code>field:{field_name}:{query}</code></p> <p>Specifies that <code>{query}</code> should be run against <code>{field_name}</code>. If enclosed in brackets, <code>{query}</code> can have nested operators.</p> <p>e.g. <code>field:keywords.en-US:(firefox NOT android)</code> will find KB documents with <code>firefox</code> and without <code>android</code> in their keywords field.</p>"},{"location":"advanced-search/#aliases","title":"Aliases","text":"<p>Each document type has a number of aliases, shown below, which allows easy searching across document types.</p> <p>e.g. using <code>field:title:firefox</code> in instant search would find both articles and questions with firefox in the title.</p>"},{"location":"advanced-search/#knowledge-base-articles","title":"Knowledge Base Articles","text":"<pre><code>.. list-table::\n    :header-rows: 1\n\n    * - Alias\n      - Maps To\n    * - ``title``\n      - ``title.{locale}``\n    * - ``content``\n      - ``content.{locale}``\n</code></pre>"},{"location":"advanced-search/#questions","title":"Questions","text":"<pre><code>.. list-table::\n    :header-rows: 1\n\n    * - Alias\n      - Maps To\n    * - ``title``\n      - ``question_title.{current_locale}``\n    * - ``content``\n      - ``question_content.{current_locale}`` or ``answer_content.{current_locale}``\n    * - ``question``\n      - ``question_content.{current_locale}``\n    * - ``answer``\n      - ``answer_content.{current_locale}``\n</code></pre>"},{"location":"advanced-search/#forum-posts","title":"Forum Posts","text":"<pre><code>.. list-table::\n    :header-rows: 1\n\n    * - Field\n      - Maps To\n    * - ``title``\n      - ``thread_title``\n</code></pre>"},{"location":"advanced-search/#boolean-operators","title":"Boolean Operators","text":""},{"location":"advanced-search/#not","title":"NOT","text":"<p><code>NOT x</code></p> <p>Specifies that the token must not exist in the document.</p>"},{"location":"advanced-search/#and","title":"AND","text":"<p><code>x AND y</code></p> <p>Specifies that both tokens must exist in the document.</p> <pre><code>.. note::\n    A quirk of our current implementation is that ``x AND y`` can return more results than ``x y``.\n    This is because ``x y`` requires both tokens to exist in the same field,\n    whereas ``x AND y`` will match across fields.\n\n    e.g. with a document like so:\n    ::\n        {\n            \"title\": \"x\",\n            \"content\": \"y\"\n        }\n\n    ``x y`` wouldn't match, but ``x AND y`` would.\n</code></pre>"},{"location":"advanced-search/#or","title":"OR","text":"<p><code>x OR y</code></p> <p>Specifies that either token must exist in the document.</p>"},{"location":"advanced-search/#exact-value-query","title":"Exact Value Query","text":"<p><code>exact:{field_name}:{value}</code></p> <p>Specifies that <code>{value}</code> should exactly match the value of (or token in) <code>{field_name}</code>.</p> <p>e.g. <code>exact:question_has_solution:false</code> will only match questions without solutions.</p>"},{"location":"advanced-search/#convenience-values","title":"Convenience Values","text":"<p>These fields take a value which will be mapped to the appropriate ID internally.</p>"},{"location":"advanced-search/#knowledge-base-articles_1","title":"Knowledge Base Articles","text":"<pre><code>.. list-table::\n    :header-rows: 1\n\n    * - Field\n      - Valid values\n    * - ``category``\n      - ``troubleshooting``,\n        ``how-to``,\n        ``how-to-contribute``,\n        ``navigation``\n</code></pre>"},{"location":"advanced-search/#range-query","title":"Range Query","text":"<p><code>range:{field_name}:{operator}:{value}</code></p> <p>Specifies that <code>{value}</code> should fall within the range of the value of <code>{field_name}</code>. <code>{field_name}</code> must be a date or numeric field.</p> <p><code>{operator}</code> can take the following values: * <code>gt</code> - greater than * <code>gte</code> - greater than or equal * <code>lt</code> - less than * <code>lte</code> - less than or equal</p> <p><code>{value}</code> can take the following formats: * a basic number e.g. <code>1</code> * a date in the form <code>yyyy-MM-dd</code> * a date and time in the form <code>yyyy-MM-dd'T'HH:mm:ss</code> * a date math value e.g. <code>now</code>, or <code>now-1d</code></p> <p>e.g. <code>range:question_created:gte:2021-05-27 AND range:question_created:lt:2021-05-28</code> will match questions created on 27<sup>th</sup> May 2021.</p> <p>e.g. <code>range:question_created:gte:now-2d</code> will match questions created in the last two days.</p>"},{"location":"advanced-search/#brackets-and-operator-precedence","title":"Brackets and Operator Precedence","text":"<p>The operators above are documented in the order they're evaluated. To adjust the order of evaluation, you can make use of brackets.</p> <p>e.g. <code>NOT firefox OR crashes</code> will match documents which either don't have firefox in them, or have crashes in them. (This can also be expressed like <code>(NOT firefox) OR crashes</code>).</p> <p>e.g. <code>NOT (firefox OR crashes)</code> will match documents which have neither firefox nor crashes in them.</p>"},{"location":"advanced-search/#document-fields","title":"Document Fields","text":"<p>Fields below with a Yes in the Locale? column require a locale code after their field name.</p> <p>e.g. to match against question content in English, you'll need to use <code>question_content.en-US</code>.</p> <p>e.g. to match against answer content in German, you'll use to use <code>answer_content.de</code>.</p> <pre><code>.. note::\n  Currently you can't search in a locale other than the one you're using SUMO in.\n  For instance, attempting to search for ``field:question_content.en-US:firefox`` on http://support.mozilla.org/de will return zero results.\n</code></pre>"},{"location":"advanced-search/#knowledge-base-articles_2","title":"Knowledge Base Articles","text":"<pre><code>.. list-table::\n    :header-rows: 1\n\n    * - Field\n      - Locale?\n      - Type\n    * - ``updated``\n      -\n      - Date\n    * - ``product_ids``\n      -\n      - Array of Keywords\n    * - ``topic_ids``\n      -\n      - Array of Keywords\n    * - ``category``\n      -\n      - Keyword\n    * - ``title``\n      - Yes\n      - Text\n    * - ``content``\n      - Yes\n      - Text\n    * - ``summary``\n      - Yes\n      - Text\n    * - ``keywords``\n      - Yes\n      - Text\n    * - ``slug``\n      - Yes\n      - Keyword\n    * - ``doc_id``\n      - Yes\n      - Keyword\n</code></pre>"},{"location":"advanced-search/#questions_1","title":"Questions","text":"<pre><code>.. list-table::\n    :header-rows: 1\n\n    * - Field\n      - Locale?\n      - Type\n    * - ``question_id``\n      -\n      - Keyword\n    * - ``question_title``\n      - Yes\n      - Text\n    * - ``question_creator_id``\n      -\n      - Keyword\n    * - ``question_content``\n      - Yes\n      - Text\n    * - ``question_created``\n      -\n      - Date\n    * - ``question_updated``\n      -\n      - Date\n    * - ``question_updated_by_id``\n      -\n      - Keyword\n    * - ``question_has_solution``\n      -\n      - Boolean\n    * - ``question_is_locked``\n      -\n      - Boolean\n    * - ``question_is_archived``\n      -\n      - Boolean\n    * - ``question_product_id``\n      -\n      - Keyword\n    * - ``question_topic_id``\n      -\n      - Keyword\n    * - ``question_taken_by_id``\n      -\n      - Keyword\n    * - ``question_taken_until``\n      -\n      - Date\n    * - ``question_tag_ids``\n      -\n      - Array of Keywords\n    * - ``question_num_votes``\n      -\n      - Integer\n    * - ``answer_content``\n      - Yes\n      - Array of Text\n    * - ``locale``\n      -\n      - Keyword\n</code></pre>"},{"location":"advanced-search/#forum-posts_1","title":"Forum Posts","text":"<pre><code>.. list-table::\n    :header-rows: 1\n\n    * - Field\n      - Type\n    * - ``thread_title``\n      - Text\n    * - ``thread_forum_id``\n      - Keyword\n    * - ``forum_slug``\n      - Keyword\n    * - ``thread_id``\n      - Keyword\n    * - ``thread_created``\n      - Date\n    * - ``thread_creator_id``\n      - Keyword\n    * - ``thread_is_locked``\n      - Boolean\n    * - ``thread_is_sticky``\n      - Boolean\n    * - ``content``\n      - Text\n    * - ``author_id``\n      - Keyword\n    * - ``created``\n      - Date\n    * - ``updated``\n      - Date\n    * - ``updated_by_id``\n      - Keyword\n</code></pre>"},{"location":"api/","title":"API","text":"<p>SUMO has a series of API endpoints to access data.</p> <p>::: contents :::</p>"},{"location":"api/#search-suggest-api","title":"Search suggest API","text":"Endpoint <p><code>/api/2/search/suggest/</code></p> Method <p><code>GET</code></p> Content type <p><code>application/json</code></p> Response <p><code>application/json</code></p> <p>The search suggest API allows you to get back kb documents and aaq questions that match specified arguments.</p> <p>Arguments can be specified in the url querystring or in the HTTP request body.</p>"},{"location":"api/#required-arguments","title":"Required arguments","text":"<p>argument         type     notes</p> <p>q                string   This is the text you\\'re querying for.</p>"},{"location":"api/#optional-arguments","title":"Optional arguments","text":"<p>+---------------+------+----------------------------------------------+ | argument      | type | notes                                        | +===============+======+==============================================+ | locale        | st   | default: <code>settings.WIKI_DEFAULT_LANGUAGE</code>    | |               | ring |                                              | |               |      | The locale code to restrict results to.      | |               |      |                                              | |               |      | Examples:                                    | |               |      |                                              | |               |      | -   <code>en-US</code>                                  | |               |      | -   <code>fr</code>                                     | +---------------+------+----------------------------------------------+ | product       | st   | default: None                                | |               | ring |                                              | |               |      | The product to restrict results to.          | |               |      |                                              | |               |      | Example:                                     | |               |      |                                              | |               |      | -   <code>firefox</code>                                | +---------------+------+----------------------------------------------+ | max_documents | int  | default: 10                                  | |               | eger |                                              | |               |      | The maximum number of documents you want     | |               |      | back.                                        | +---------------+------+----------------------------------------------+ | max_questions | int  | default: 10                                  | |               | eger |                                              | |               |      | The maximum number of questions you want     | |               |      | back.                                        | +---------------+------+----------------------------------------------+</p>"},{"location":"api/#responses","title":"Responses","text":"<p>All response bodies are in JSON.</p>"},{"location":"api/#http-200-success","title":"HTTP 200: Success","text":"<p>With an HTTP 200, you\\'ll get back a set of results in JSON.</p> <pre><code>{\n    \"documents\": [\n        {\n            \"id\": ...                  # id of kb article\n            \"title\": ...               # title of kb article\n            \"url\": ...                 # url of kb article\n            \"slug\": ...                # slug of kb article\n            \"locale\": ...              # locale of the article\n            \"products\": ...            # list of products for the article\n            \"topics\": ...              # list of topics for the article\n            \"summary\": ...             # paragraph summary of kb article (plaintext)\n            \"html\": ...                # html of the article\n        }\n        ...\n    ],\n    \"questions\": [\n        {\n            \"id\": ...                  # integer id of the question\n            \"answers\": ...             # list of answer ids\n            \"content\": ...             # content of question (in html)\n            \"created\": ...             # datetime stamp in iso-8601 format\n            \"creator\": ...             # JSON object describing the creator\n            \"involved\": ...            # list of JSON objects describing everyone who\n                                         participated in the question\n            \"is_archived\": ...         # boolean for whether this question is archived\n            \"is_locked\": ...           # boolean for whether this question is locked\n            \"is_solved\": ...           # boolean for whether this question is solved\n            \"is_spam\": ...             # boolean for whether this question is spam\n            \"is_taken\": ...            # FIXME:\n            \"last_answer\": ...         # id for the last answer\n            \"num_answers\": ...         # total number of answers\n            \"locale\": ...              # the locale for the question\n            \"metadata\": ...            # metadata collected for the question\n            \"tags\": ...                # tags for the question\n            \"num_votes_past_week\": ... # the number of votes in the last week\n            \"num_votes\": ...           # the total number of votes\n            \"product\": ...             # the product\n            \"solution\": ...            # id of answer marked as a solution if any\n            \"taken_until\": ...         # FIXME:\n            \"taken_by\": ...            # FIXME:\n            \"title\": ...               # title of the question\n            \"topic\": ...               # FIXME:\n            \"updated_by\": ...          # FIXME:\n            \"updated\": ...             # FIXME:\n        },\n        ...\n    ]\n}\n</code></pre>"},{"location":"api/#examples","title":"Examples","text":"<p>Using curl:</p> <pre><code>curl -X GET \"http://localhost:8000/api/2/search/suggest/?q=videos\"\n\ncurl -X GET \"http://localhost:8000/api/2/search/suggest/?q=videos&amp;max_documents=3&amp;max_questions=3\"\n\ncurl -X GET \"http://localhost:8000/api/2/search/suggest/\" \\\n     -H \"Content-Type: application/json\" \\\n     -d '\n{\n   \"q\": \"videos\",\n   \"max_documents\": 3,\n   \"max_questions\": 0\n}'\n</code></pre>"},{"location":"api/#locales-api","title":"Locales API","text":"<p>All locales supported by SUMO.</p> <p>Example request:</p> <pre><code>GET /api/2/locales/ HTTP/1.1\nAccept: application/json\n</code></pre> <p>Example response:</p> <pre><code>HTTP/1.0 200 OK\nVary: Accept, X-Mobile, User-Agent\nAllow: OPTIONS, GET\nX-Frame-Options: DENY\nContent-Type: application/json\n\n{\n   \"vi\": {\n      \"name\": \"Vietnamese\",\n      \"localized_name\": \"Ti\\u1ebfng Vi\\u1ec7t\",\n      \"aaq_enabled\": false\n   },\n   \"el\": {\n      \"name\": \"Greek\",\n      \"localized_name\": \"\\u0395\\u03bb\\u03bb\\u03b7\\u03bd\\u03b9\\u03ba\\u03ac\",\n      \"aaq_enabled\": false\n   },\n   \"en-US\": {\n      \"name\": \"English\",\n      \"localized_name\": \"English\",\n      \"aaq_enabled\": true\n   }\n}\n</code></pre> reqheader Accept <p>application/json</p> resheader Content-Type <p>application/json</p> statuscode 200 <p>no error</p>"},{"location":"architectural-decisions/","title":"Architectural Decision Records","text":"<p>We record major architectural decisions for Kitsune/SUMO in Architecture Decision Records (ADR), as described by Michael Nygard.</p> <p>Our current ADRs are listed in the navigation.</p>"},{"location":"badges/","title":"Badges","text":"<p>::: warning ::: title Warning :::</p> <p>This section of documentation may be outdated. :::</p> <p>Badges in kitsune are based off of Django Badger,</p> <p>As of Q3 2018, kitsune issues four badges per calendar year:</p> <ol> <li>KB Badge</li> <li>L10n Badge</li> <li>Support Forum Badge</li> <li>Army of Awesome Badge</li> </ol> <p>A list of active badges can be seen at https://support.mozilla.org/badges/.</p>"},{"location":"badges/#kb-badge-l10n-badge","title":"KB Badge &amp; L10n Badge","text":"<p>The KB Badge is awarded after a user has reached 10 approved English edits on knowledge base articles.</p> <p>The L10n Badge is awarded after a user has reached 10 approved translation edits on knowledge base articles.</p> <p>Logic for both badges can be found in <code>kitsune.wiki.badges</code>.</p> <p>The number of edits needed is configurable in <code>settings.BADGE_LIMIT_L10N_KB</code>.</p>"},{"location":"badges/#support-forum-badge","title":"Support Forum Badge","text":"<p>The Support Forum Badge is awarded after a user has reached 30 support forum replies.</p> <p>Logic for awarding this badge can be found in <code>kitsune.questions.badges</code>.</p> <p>The number of replies needed is configurable in <code>settings.BADGE_LIMIT_SUPPORT_FORUM</code>.</p>"},{"location":"badges/#army-of-awesome-badge","title":"Army of Awesome Badge","text":"<p>::: warning ::: title Warning :::</p> <p>This badge is no longer available. :::</p> <p>The Army of Awesome Badge is awarded when a user has tweeted 50 Army of Awesome replies.</p>"},{"location":"badges/#badge-creation","title":"Badge Creation","text":"<p>Badges are either created manually through the Django Admin or created automatically via <code>get_or_create_badge</code> in <code>kitsune.kbadge.utils</code>.</p> <p>Creation through the Django Admin is the usual and preferred method.</p>"},{"location":"browser_permissions/","title":"Browser permissions","text":""},{"location":"browser_permissions/#elevated-browser-permissions","title":"Elevated Browser Permissions","text":"<p>support.mozilla.org has certain elevated permissions in Firefox, shown in the Firefox source code, allowing it to control various aspects of Firefox's UI and retrieve debugging information.</p> <p>Testing this on our other deployments or locally requires extra configuration and setup.</p>"},{"location":"browser_permissions/#adding-permissions","title":"Adding permissions","text":"<p>There's a couple of ways to add permissions, one which happens instantly but doesn't survive browser restarts, and the other which requires a restart to enable but also persists across restarts:</p>"},{"location":"browser_permissions/#temporarily","title":"Temporarily","text":"<p>This method requires us to execute an expression in the Browser Console, so we need to enable the Browser Console command line.</p> <p>Once that's enabled, follow the instructions on how to open the Browser Console, then run the following command, substituting <code>&lt;origin&gt;</code> and <code>&lt;permission&gt;</code> where relevant based on the instructions in the following sections:</p> <pre><code>Services.perms.addFromPrincipal(\n  Services.scriptSecurityManager.createContentPrincipalFromOrigin(\"&lt;origin&gt;\"),\n  \"&lt;permission&gt;\",\n  Services.perms.ALLOW_ACTION\n);\n</code></pre> <p>Reload the tab containing the page which is attempting to use these elevated permissions and it should have them.</p>"},{"location":"browser_permissions/#permanently","title":"Permanently","text":"<p>Permissions granted with the above method are cleared once the browser restarts. To enable them permanently then a slightly different approach must be taken.</p> <p>First copy the contents of <code>resource://app/defaults/permissions</code> to a local file.</p> <p>Then in <code>about:config</code> change the <code>permissions.manager.defaultsUrl</code> preference to the path of the file you just created, for example <code>file:///path_to_your_kitsune_dir/permissions</code>.</p> <p>Now add a line enabling the relevant <code>&lt;permission&gt;</code> for the relevant <code>&lt;origin&gt;</code>:</p> <pre><code>origin  &lt;permission&gt;    1   &lt;origin&gt;\n</code></pre> <p>Finally restart Firefox to pick up these changes. Any time you want to change the permissions an origin has you'll also need to restart Firefox.</p>"},{"location":"browser_permissions/#testing-locally","title":"Testing locally","text":"<p>Firefox only grants permissions to <code>https</code> origins, so we need to serve our local instance over <code>https</code>. The easiest way to do this is to set up a reverse proxy, with a tool like <code>local-ssl-proxy</code>:</p> <pre><code>npm install -g local-ssl-proxy\n</code></pre> <p>Then run the proxy:</p> <pre><code>local-ssl-proxy -n 127.0.0.1 --source 8001 --target 8000\n</code></pre> <p>And access Kitsune at <code>https://127.0.0.1:8001</code>, which will also be your <code>&lt;origin&gt;</code>.</p>"},{"location":"browser_permissions/#remote-troubleshooting-aboutsupport-api","title":"Remote Troubleshooting (about:support) API","text":"<p>The remote troubleshooting API allows support.mozilla.org to access the contents of the <code>about:support</code> page.</p> <p>An additional permission needs to be granted to any origin you want to test this API on. Open <code>about:config</code> and append the relevant <code>&lt;origin&gt;</code> to the <code>webchannel.allowObject.urlWhitelist</code> preference.</p> <p>Then grant the permission as above, where <code>&lt;permission&gt;</code> is <code>remote-troubleshooting</code>.</p>"},{"location":"browser_permissions/#examples","title":"Examples","text":"<p>To enable permanently on staging:</p> <ol> <li> <p>Add <code>https://support.allizom.org</code> to <code>webchannel.allowObject.urlWhitelist</code>.</p> </li> <li> <p>Add <code>origin  remote-troubleshooting  1   https://support.allizom.org</code> to your permissions file.</p> </li> <li> <p>Restart Firefox.</p> </li> </ol>"},{"location":"browser_permissions/#uitour-api","title":"UITour API","text":"<p>The UITour API allows support.mozilla.org to control various aspects of the Firefox UI.</p> <p>It can be enabled by granting the permission as above, where <code>&lt;permission&gt;</code> is <code>uitour</code>.</p> <p>However a far simpler way to enable it is to set a couple of custom preferences in <code>about:config</code> as explained in the Bedrock docs.</p>"},{"location":"celery/","title":"Celery","text":"<p>Kitsune uses Celery to enable offline task processing for long-running jobs like sending email notifications and re-rendering the Knowledge Base.</p> <p>Though Celery supports multiple message backends, we use Redis.</p>"},{"location":"celery/#when-is-celery-appropriate","title":"When is Celery Appropriate","text":"<p>You can use Celery to do any processing that doesn\\'t need to happen in the current request-response cycle. Examples are generating thumbnails, sending out notification emails, updating content that isn\\'t about to be displayed to the user, and others.</p> <p>Ask yourself the question: \\\"Is the user going to need this data on the page I\\'m about to send them?\\\" If not, using a Celery task may be a good choice.</p>"},{"location":"celery/#configuring-and-running","title":"Configuring and Running","text":"<p>Celery will automatically start when you run:</p> <pre><code>make run\n</code></pre> <p>We set some reasonable defaults for Celery in <code>settings.py</code>. These can be overriden in <code>.env</code>.</p> <p>If you don\\'t want to use Celery, you can set this in <code>.env</code>:</p> <pre><code>CELERY_TASK_ALWAYS_EAGER = True\n</code></pre> <p>Setting this to <code>True</code> causes all task processing to be done online. This is useful when debugging tasks, for instance.</p> <p>You can also configure the concurrency. Here is the default:</p> <pre><code>CELERY_WORKER_CONCURRENCY = 4\n</code></pre> <p>Then to restart the Celery workers, you just need to run:</p> <pre><code>docker-compose restart celery\n</code></pre>"},{"location":"contactus/","title":"Contact us","text":""},{"location":"contactus/#sumo-contributor-forums","title":"SUMO contributor forums","text":"<p>If you\\'re a SUMO contributor, then consider using the contributor forums. This is the place for SUMO community discussions.</p>"},{"location":"contactus/#kitsune-hackers","title":"Kitsune hackers","text":"<p>If you\\'re hacking on the Kitsune code and have questions, ping us on Matrix.</p> <p>We hang out in #support-platform:mozilla.org.</p> <p>If you ask something and all you get is silence, then it\\'s probably the case that we\\'re not around. Please try pinging us again.</p> <p>Current developers:</p> <ul> <li>Tasos Katsoulas (tasos)</li> <li>Ryan Johnson (ryan)</li> <li>Smith Ellis (smith)</li> </ul>"},{"location":"contributors/","title":"Join this project!","text":"<p>Kitsune is the software that runs SUMO (support.mozilla.org) which provides support for Firefox and other Mozilla software.</p> <p>Interested in helping out? Here's a bunch of things we need your help with.</p>"},{"location":"contributors/#help-with-support","title":"Help with support!","text":"<p>First off, you can help people get the most out of Firefox by joining the awesome support community. This community not only helps people with their Firefox issues, but is also the front line in helping drive Firefox development.</p> <p>For more information on this, see the quickstart guide on the SUMO site.</p>"},{"location":"contributors/#help-reporting-bugs","title":"Help reporting bugs","text":"<p>Please report any bugs you find with Kitsune on Bugzilla: https://bugzilla.mozilla.org/enter_bug.cgi?product=support.mozilla.org</p>"},{"location":"contributors/#help-with-hacking","title":"Help with hacking!","text":"<p>First step is to set up Kitsune so you can run it and hack on it. If you have problems, please let us know!</p>"},{"location":"contributors/#help-with-making-kitsune-easier-for-hacking-on","title":"Help with making Kitsune easier for hacking on!","text":"<p>We're working on making Kitsune easier to hack on. This entails:</p> <ul> <li>reducing the steps it takes to get Kitsune running down to a smaller     minimal set</li> <li>making this documentation better</li> <li>providing better resources for people who are interested in helping     out</li> <li>providing better scripts to automate installing and maintaining     Kitsune</li> </ul> <p>Any thoughts you have on making this easier are much appreciated. Further, if you could help us, that\\'d be valuable to us and all those who follow in your footsteps.</p>"},{"location":"conventions/","title":"Conventions","text":"<p>This document contains coding conventions, and things to watch out for, etc.</p>"},{"location":"conventions/#coding-conventions","title":"Coding conventions","text":"<p>We follow most of the practices as detailed in the Mozilla webdev bootcamp guide.</p> <p>It is recommended that you install pre-commit</p>"},{"location":"conventions/#type-hints","title":"Type hints","text":"<p>When creating and/or modifying Python functions/methods, we add type hints to their arguments and result, but only when it makes sense. See our Architectural Decision Record for more details.</p>"},{"location":"conventions/#git-conventions","title":"Git conventions","text":""},{"location":"conventions/#git-workflow","title":"Git workflow","text":"<p>See patching for how we use Git, branches and merging.</p>"},{"location":"conventions/#git-commit-messages","title":"Git commit messages","text":"<p>Git commit messages should have the following form:</p> <pre><code>[bug xxxxxxx] Short summary\n\nLonger explanation with paragraphs and lists and all that where\neach line is under 72 characters.\n\n* bullet 1\n* bullet 2\n\nEtc. etc.\n</code></pre> <p>Summary line should be capitalized, short and should not exceed 50 characters. Why? Because this is a convention many git tools take advantage of.</p> <p>If the commit relates to a bug, the bug should show up in the summary line in brackets.</p> <p>There should be a blank line between the summary and the rest of the commit message. Lines should not exceed 72 characters.</p> <p>See these guidelines for some more explanation.</p>"},{"location":"conventions/#git-resources-and-tools","title":"Git resources and tools","text":"<p>See Webdev bootcamp guide for:</p> <ul> <li>helpful resources for learning git</li> <li>helpful tools</li> </ul>"},{"location":"deployments/","title":"Kitsune Deployments","text":"<p>This documents the current development (dev), staging and production (prod) servers for the <code>support.mozilla.com</code> instance of Kitsune.</p>"},{"location":"deployments/#the-source","title":"The Source","text":"<p>All of the source code for Kitsune lives in a single Github repo.</p>"},{"location":"deployments/#branches","title":"Branches","text":""},{"location":"deployments/#main","title":"main","text":"<p>The <code>main</code> branch is our main integration points. All new patches should be based on the latest <code>main</code> (or rebased to it).</p> <p>Pull requests are created from those branches. Pull requests may be opened at any time, including before any code has been written.</p> <p>Pull requests get reviewed.</p> <p>Once reviewed, the branch is merged into <code>main</code>, except in special cases such as changes that require re-indexing. See Changes that involve reindexing.</p> <p>We deploy to production from <code>main</code>.</p>"},{"location":"deployments/#deploying","title":"Deploying","text":"<p>For our infrastructure instructions see Kubernetes Support Guide.</p>"},{"location":"deployments/#servers","title":"Servers","text":""},{"location":"deployments/#development","title":"Development","text":"<p>https://support-dev.allizom.org/</p> <p>We use dev primarily to develop infrastructure changes.</p>"},{"location":"deployments/#staging","title":"Staging","text":"<p>https://support.allizom.org/</p> <p>We deploy to stage anything we want to test including deployments themselves.</p>"},{"location":"deployments/#production","title":"Production","text":"<p>https://support.mozilla.org/</p>"},{"location":"development/","title":"Development","text":"<p>This covers loosely how we do big feature changes.</p>"},{"location":"development/#changes-that-involve-new-python-dependencies","title":"Changes that involve new Python dependencies","text":"<p>Warning</p> <p>This section of documentation may be outdated.</p> <p>All python dependencies have an associated hash (or several) that are checked at download time. This ensures malicious code doesn't sneak in through dependencies being hacked, and also makes sure we always get the exact code we developed against. Changes in dependencies, malicious or not, will set off red flags and require human intervention.</p> <p>A pip requirement stanza with hashes looks something like this:</p> <pre><code>Django==1.8.15 \\\n    --hash=sha256:e2e41aeb4fb757575021621dc28fceb9ad137879ae0b854067f1726d9a772807 \\\n    --hash=sha256:863e543ac985d5cfbce09213fa30bc7c802cbdf60d6db8b5f9dab41e1341eacd\n</code></pre> <p>hash lines can be repeated, and other comments can be added. The stanza is delimited by non-comment lines (such as blank lines or other requirements).</p> <p>Fortunately we do not need to add or edit those manaully. Using pip-compile-multi we list only our top-level dependencies in [requirements/*.in]{.title-ref}. To add a dependency, put it in the appropriate [requirements/*.in]{.title-ref} file, then compile:</p> <pre><code>pip-compile-multi -g default\n</code></pre>"},{"location":"development/#changes-that-involve-database-migrations","title":"Changes that involve database migrations","text":"<p>Any changes to the database (model fields, model field data, adding permissions, ...) require a migration.</p>"},{"location":"development/#running-migrations","title":"Running migrations","text":"<p>To run migrations, you do:</p> <pre><code>$ ./manage.py migrate\n</code></pre> <p>It will perform any migrations that haven't been performed for all apps.</p>"},{"location":"development/#creating-a-schema-migration","title":"Creating a schema migration","text":"<p>To create a new migration the automatic way:</p> <ol> <li> <p>make your model changes</p> </li> <li> <p>run:</p> <pre><code>./manage.py makemigrations &lt;app&gt;\n</code></pre> <p>where <code>&lt;app&gt;</code> is the app name (sumo, wiki, questions, ...).</p> </li> <li> <p>run the migration on your machine:</p> <pre><code>./manage.py migrate\n</code></pre> </li> <li> <p>run the tests to make sure everything works</p> </li> <li> <p>add the new migration files to git</p> </li> <li> <p>commit</p> </li> </ol> <p>Info</p> <p>Django documentation: Adding migrations to apps</p>"},{"location":"development/#creating-a-data-migration","title":"Creating a data migration","text":"<p>Creating data migrations is pretty straight-forward in most cases.</p> <p>To create a data migration the automatic way:</p> <ol> <li> <p>run:</p> <pre><code>./manage.py makemigrations --empty &lt;app&gt;\n</code></pre> <p>where <code>&lt;app&gt;</code> is the app name (sumo, wiki, questions, ...).</p> </li> <li> <p>edit the data migration you just created to do what you need it to     do</p> </li> <li> <p>make sure to add [reverse_code]{.title-ref} arguments to all     [RunPython]{.title-ref} operations which undoes the changes</p> </li> <li> <p>add a module-level docstring explaining what this migration is doing</p> </li> <li> <p>run the migration forwards and backwards to make sure it works     correctly</p> </li> <li> <p>add the new migration file to git</p> </li> <li> <p>commit</p> </li> </ol> <p>Info</p> <p>Django documentation: Data Migrations</p>"},{"location":"development/#data-migrations-for-data-in-non-kitsune-apps","title":"Data migrations for data in non-kitsune apps","text":"<p>If you're doing a data migration that adds data to an app that's not part of kitsune, but is instead a library (e.g. django-waffle), then create the data migration in the sumo app and add a dependency to the latest migration in the library app.</p> <p>For example, this adds a dependency to django-waffle's initial migration:</p> <pre><code>class Migration(migrations.Migration):\n\n    dependencies = [\n        ...\n        ('waffle', '0001_initial'),\n        ...\n    ]\n</code></pre>"},{"location":"development/#changes-that-involve-reindexing","title":"Changes that involve reindexing","text":"<p>With Elastic Search, it takes a while to reindex. We need to be able to reindex without taking down search.</p> <p>This walks through the workflow for making changes to our Elastic Search code that require reindexing.</p>"},{"location":"development/#things-about-non-trivial-changes","title":"Things about non-trivial changes","text":"<ol> <li>We should roll multiple reindex-requiring changes into megapacks     when it makes sense and does not add complexity.</li> <li>Developers should test changes with recent sumo dumps.</li> </ol>"},{"location":"development/#workflow-for-making-the-changes","title":"Workflow for making the changes","text":"<ol> <li> <p>work on the changes in a separate branch (just like everything else     we do)</p> </li> <li> <p>make a pull request</p> </li> <li> <p>get the pull request reviewed</p> </li> <li> <p>rebase the changes so they're in two commits:</p> <ol> <li>a stage 1 commit that changes <code>ES_WRITE_INDEXES</code>, updates the     mappings and updates the indexing code</li> <li>a stage 2 commit that changes <code>ES_INDEXES</code>, changes     <code>ES_WRITE_INDEXES</code>, and changes the search view code</li> </ol> <p>Avoid cosmetic changes that don't need to be made (e.g. pep-8 fixes, etc.)</p> </li> <li> <p>push those changes to the same pull request</p> </li> <li> <p>get those two changes reviewed</p> </li> </ol> <p>Once that's ok, then that branch should get updated from main, then pushed to stage to get tested.</p> <p>That branch should not land in main, yet.</p>"},{"location":"development/#workflow-for-reviewing-changes","title":"Workflow for reviewing changes","text":"<p>Go through and do a normal review.</p> <p>After everything looks good, the developer should rebase the changes so they\\'re in a stage 1 commit and a stage 2 commit.</p> <p>At that point:</p> <ol> <li>Verify each commit individually. Make sure the code is correct. Make     sure the tests pass. Make sure the site is functional.</li> <li>Verify that the <code>ES_INDEXES</code> and <code>ES_WRITE_INDEXES</code> settings have     the correct values in each commit.</li> </ol>"},{"location":"development/#workflow-for-pushing-changes-to-stage","title":"Workflow for pushing changes to stage","text":"<p>Don't land the changes in main, yet!</p> <p>If you hit problems, deploy the main branch back to the stage server and go back to coding/fixing.</p> <ol> <li>Push the branch you have your changes in to the official     mozilla/kitsune remote.</li> <li>Deploy the stage 1 commit to stage.</li> <li>Verify that search still works.</li> <li>Verify that the index settings are correct---look at the     <code>ES_INDEXES</code> and <code>ES_WRITE_INDEXES</code> values.</li> <li>Destructively reindex.</li> <li>Deploy the stage 2 commit to stage.</li> <li>Verify that search still works.</li> <li>Verify that the index settings are correct---look at the     <code>ES_INDEXES</code> and <code>ES_WRITE_INDEXES</code> values.</li> <li>Verify bugs that were fixed with the new search code.</li> </ol>"},{"location":"development/#workflow-for-pushing-those-changes-to-production","title":"Workflow for pushing those changes to production","text":"<p>If we're also doing a production push, first push next to production and verify that everything is fine. Then continue.</p> <ol> <li>Tell the other sumo devs to hold off on pushing to main branch and     deploying. Preferably by email and IRC.</li> <li>Once you\\'ve told everyone, land the changes in main.</li> <li>Deploy the stage 1 commit to production.</li> <li>Verify that search works.</li> <li>Destructively reindex to the new write index.</li> <li>When reindexing is done, push the stage 2 commit to production.</li> <li>Verify that search works.</li> <li>Verify bugs that were fixed with the new search code.</li> </ol> <p>Pretty sure this process allows us to back out at any time with minimal downtime.</p>"},{"location":"development/#on-the-next-day","title":"On the next day","text":"<p>If everything is still fine, then merge the special branch into main and delete the old read index.</p> <p>Announce \"STUCK THE LANDING!\" after a successful mapping change deployment.</p>"},{"location":"elastic_search/","title":"Elastic search","text":""},{"location":"elastic_search/#search","title":"Search","text":""},{"location":"elastic_search/#development-tips","title":"Development tips","text":""},{"location":"elastic_search/#adding-fields-to-a-live-index","title":"Adding fields to a live index","text":"<p>Elastic supports adding new fields to an existing mapping, along with some other operations: https://www.elastic.co/guide/en/elasticsearch/reference/7.9/mapping.html#add-field-mapping</p> <p>To know whether a change you make to a Document will work in prod, try it locally having already set up the mapping:</p> <pre><code>./manage.py es_init --limit TestDocument\n\n... make changes to TestDocument ...\n\n./manage.py es_init --limit TestDocument\n</code></pre> <p>If that fails with an error, you'll need to create a new index with the new mapping, and reindex everything into that index.</p> <p>However if it succeeds then it should also work on prod.</p> <p>Once the changes are deployed to prod, and the mapping is updated with <code>es_init</code>, some documents may need to be reindexed. This is because we disable dynamic mapping in <code>SumoDocument</code>, to prevent a dynamic mapping of the wrong type being set up before <code>es_init</code> was able to be run during a deployment.</p> <p>So to ensure no data is missing from the index, run something like:</p> <pre><code>./manage.py es_reindex --limit TestDocument --updated-after &lt;datetime of deploy&gt; --updated-before &lt;datetime of mapping update&gt;\n</code></pre>"},{"location":"elastic_search/#indexing-performance","title":"Indexing performance","text":"<p>When adding or editing elastic documents, you might want to add the <code>--print-sql-count</code> argument when testing out your changes, to see how many SQL queries are being executed:</p> <pre><code>CELERY_TASK_ALWAYS_EAGER=True ./manage.py es_reindex --print-sql-count --sql-chunk-size=100 --count=100\n</code></pre> <p>If the result is much less than 100, then you have a well optimized document for indexing. However, if the result is some multiple of 100, then unfortunately one or more SQL queries are being executed for each instance being indexed. Consider using some combination of <code>select_related</code>, <code>prefetch_related</code> or annotations to bring that number down.</p>"},{"location":"elastic_search/#datetimes-and-timezones","title":"Datetimes and timezones","text":"<p>As a first step in our migration to using timezone-aware datetimes throughout the application, all datetimes stored in Elastic should be timezone-aware, so as to avoid having to migrate them later.</p> <p>If inheriting from <code>SumoDocument</code>, any naive datetime set in a <code>Date</code> field will be automatically converted into a timezone-aware datetime, with the naive datetime assumed to be in the application's <code>TIME_ZONE</code>.</p> <p>To avoid loss of precision around DST switches, where possible aware datetimes should be set. To generate an aware datetime do:</p> <pre><code>import datetime, timezone\n\ndatetime.now(timezone.utc)\n</code></pre> <p>This should be used instead of <code>django.utils.timezone.now()</code> as that returns a naive or aware datetime depending on the value of <code>USE_TZ</code>, whereas we want datetimes in Elastic to always be timezone-aware.</p>"},{"location":"elastic_search/#print-elasticsearch-queries-in-your-development-console","title":"Print ElasticSearch queries in your development console","text":"<p>You can set the following variable in your .env file to enable the logging of the queries that are sent to your local ElasticSearch instance.</p> <pre><code>ES_ENABLE_CONSOLE_LOGGING=True\n</code></pre>"},{"location":"elastic_search/#simulate-slow-and-out-of-order-query-responses","title":"Simulate slow and out of order query responses","text":"<p>To test how Instant Search behaves with slow and out of order responses you can add a snippet like this:</p> <pre><code>from time import sleep\nfrom random import randint\nsleep(randint(1, 10))\n</code></pre> <p>to <code>kitsune.search.views.simple_search</code>.</p>"},{"location":"elastic_search/#synonyms","title":"Synonyms","text":"<p>The <code>kitsune/search/dictionaries/synonyms</code> path contains a text file for each of our search-enabled locales, where synonyms are in the Solr format.</p> <p><code>expand</code> defaults to <code>True</code>, so synonyms with no explicit mapping resolve to all elements in the list. That is to say:</p> <pre><code>start, open, run\n</code></pre> <p>is equivalent to:</p> <pre><code>start, open, run =&gt; start, open, run\n</code></pre> <p>It's also worth noting that these synonyms are applied at query time, not index time.</p> <p>That is to say, if a document contained the phrase:</p> <p>Firefox won't play music.</p> <p>and we had a synonym set up as:</p> <pre><code>music =&gt; music, audio\n</code></pre> <p>Then the search query:</p> <p>firefox won't play audio</p> <p>would not match that document.</p>"},{"location":"elastic_search/#hyponyms-and-hypernyms-subtypes-and-supertypes","title":"Hyponyms and hypernyms (subtypes and supertypes)","text":"<p>The synonym files can also be used to define relations between hyponyms and hypernyms (subtypes and supertypes).</p> <p>For example, a user searching for or posting about a problem with Facebook could use the phrase \"Facebook isn't working\", or \"social media isn't working\". Another user searching for or posting about a problem with Twitter could use the phrase \"Twitter isn't working\", or \"social media isn't working\".</p> <p>A simple synonym definition like:</p> <pre><code>social, facebook, face book, twitter\n</code></pre> <p>isn't sufficient here, as a user querying about a problem with Facebook clearly doesn't have one with Twitter.</p> <p>Similarly a rule like:</p> <pre><code>social =&gt; social, facebook, face book, twitter\n</code></pre> <p>only captures the case where a user has posted about Facebook not working and searched for social media not working, not the reverse.</p> <p>So in this case a set of synonyms should be defined, like so:</p> <pre><code>social, facebook, face book\nsocial, twitter\n</code></pre> <p>With the hypernyms (supertypes) defined across all lines, and the hyponyms (subtypes) defined on one line.</p> <p>This way, a search for \"social\" would also become one for \"facebook\", \"face book\" and \"twitter\". Whereas a search for \"twitter\" would also become one for \"social\", but not \"facebook\" or \"face book\".</p>"},{"location":"elastic_search/#interaction-with-the-rest-of-the-analysis-chain","title":"Interaction with the rest of the analysis chain","text":"<p>All the analyzers above the synonym token filter in the analyzer chain are also applied to the synonyms, such as our tokenizers, stemmers and stop word filters.</p> <p>This means it's not necessary to specify the plural or conjugated forms of words, as post-analysis they should end up as the same token.</p> <p>Hyphen-separated and space separated words will analyze to the same set of tokens.</p> <p>For instance in en-US, all these synonyms would do nothing at all:</p> <pre><code>de activate, de-activate\nload, loading, loaded\nbug, bugs\n</code></pre>"},{"location":"elastic_search/#stop-words","title":"Stop words","text":"<p>Synonyms containing stop words (such as \"in\" or \"on\") must be treated with care, as the stop words will also be filtered out of the synonyms.</p> <p>For example, these two rules produce the same result in the en-US analysis chain:</p> <pre><code>addon, add on\naddon, add\n</code></pre> <p>So a character mapping should be used to turn phrases containing those stop words into ones which don't. Those resulting phrases can then be used in the synonyms definition.</p>"},{"location":"elastic_search/#applying-to-all-locales","title":"Applying to all locales","text":"<p>There's also an <code>_all.txt</code> file, which specifies synonyms which should be applied across all locales. Suitable synonyms here include brand names or specific technical terms which won't tend to be localized.</p>"},{"location":"elastic_search/#updating","title":"Updating","text":"<p>In development synonyms can be updated very easily. Save your changes in the text file and run:</p> <pre><code>./manage.py es_init --reload-search-analyzers\n</code></pre> <p>If no other changes were made to the index configurations, then this should apply successfully, and your already-indexed data will persist within the index and not require any indexing (because these synonyms are applied at query time).</p>"},{"location":"elastic_search/#on-production","title":"On production","text":"<p>The synonym files need to be put in a bundle and uploaded to the Elastic Cloud.</p> <p>Run the <code>bin/create_elastic_bundle.sh</code> script to create a zip file with the appropriate directory structure. (You'll need to have <code>zip</code> installed for this command to work.)</p> <p>Then, either create an extension, or update the previously created extension.</p> <p>And in either case, update the deployment configuration with the custom extension.</p> <pre><code>.. Note::\n  When updating the deployment after updating an already-existing extension,\n  Elastic Cloud may say that no changes are being applied.\n  That isn't true,\n  and through testing it seems like the extension is being updated,\n  and the search analyzers are being reloaded automatically.\n\n  From testing,\n  this seems to be the only approach to update and reload synonyms on the Elastic Cloud.\n  Updating the extension,\n  restarting the cluster and using the reload-search-analyzers command *won't* work.\n\n  Thankfully there's an open issue upstream to make managing synonyms easier with an API:\n  https://github.com/elastic/elasticsearch/issues/38523\n</code></pre>"},{"location":"elastic_search/#character-mappings","title":"Character mappings","text":"<p>Character mappings cannot be dynamically updated, this is because they're applied at index time. So any changes to a character mapping requires a re-index.</p> <p>Taking the addon example from above, we'd want to create character mappings like:</p> <pre><code>[\n  \"add on =&gt; addon\",\n  \"add-on =&gt; addon\",\n]\n</code></pre> <p>Post-tokenization <code>addon</code> doesn't contain an <code>on</code> token, so this is a suitable phrase to replace with.</p> <p>Unlike synonyms, character mappings are applied before any other part of the analysis chain, so space separated and hyphen-separated phrases need to both be added.</p> <p>In theory plural and conjugated forms of words also need to be specified, however in practice plural words tend to be covered by the singular replacement as well (e.g. \"add on\" is a substring in \"add ons\", so \"add ons\" is replaced by \"addons\") and there is marginal benefit to defining every single conjugation of a verb.</p>"},{"location":"email/","title":"Email from Kitsune","text":"<p>The default settings for Kitsune do not send email. However, outgoing email is printed to the the command line.</p>"},{"location":"email/#viewing-email-through-mailcatcher","title":"Viewing email through Mailcatcher","text":"<p>To view the contents of outgoing email in a slightly easier form than the command line, Mailcatcher can be used. This still won\\'t send the email, but show a web-based \\\"outbox\\\" with the contents of all email which would be sent if Kitsune was hooked up to an email server.</p> <p>The docker-compose config includes a mailcatcher container, which can be brought up with:</p> <pre><code>docker-compose up mailcatcher\n</code></pre> <p>Kitsune should then be configured to use it:</p> <pre><code>EMAIL_LOGGING_REAL_BACKEND = django.core.mail.backends.smtp.EmailBackend\nEMAIL_HOST = mailcatcher\nEMAIL_HOST_USER =\nEMAIL_HOST_PASSWORD =\nEMAIL_PORT = 1025\nEMAIL_USE_TLS = False\n</code></pre> <p>Now all outgoing email will be captured, and can be viewed through http://localhost:1080/.</p>"},{"location":"frontend/","title":"Frontend","text":""},{"location":"frontend/#frontend-infrastructure","title":"Frontend Infrastructure","text":"<p>We use Webpack to manage our frontend assets. Its configuration lives in <code>webpack.config.js</code>, which imports files from  the <code>webpack/</code> folder.</p> <p>To build the development Webpack bundle run <code>npm run webpack:build</code>. To watch files (excluding the Webpack configuration files) and automatically rebuild the development Webpack bundle when they change, run <code>npm run webpack:watch</code>.</p> <p>To build a production Webpack bundle run <code>npm run webpack:build:prod</code>.</p> <p>Webpack puts its build output in the <code>dist/</code> folder, which is picked up by Django staticfiles.</p>"},{"location":"frontend/#entry-points","title":"Entry points","text":"<p><code>webpack/entrypoints.js</code> defines each of our entry points, and the files that should be bundled into them.</p> <p>For now this is very verbose, as it mirrors the configuration we used in our old Django Pipeline setup. However over time we'll leverage the ability to import libraries directly in the JS files which require them, reducing the number of files we need to list here.</p> <p>When building a development bundle, we generate sourcemaps to make in-browser debugging easier.</p> <p>When building a production bundle, we add a hash to the output file names, to allow for cache-busting on staging and production.</p>"},{"location":"frontend/#loading-in-django","title":"Loading in Django","text":"<p>We use the HtmlWebpackPlugin to generate HTML files for each of our entry points, which includes the script tags (and link tags, explained in the CSS section below) needed to load the hashed chunks that form each entry point. This configuration lives in <code>webpack/entrypoints-html.js</code>.</p> <p>In Django, templates can set the <code>scripts</code> variable to specify which entry points should be loaded for that template.</p>"},{"location":"frontend/#loading-css","title":"Loading CSS","text":"<p>There is a special entry point <code>screen</code> which contains all our CSS, and is treated slightly differently by <code>webpack/entrypoints-html.js</code>. Since Webpack is primarily a JS bundler it emits an empty JS file, which we have no need to include in our site, so <code>webpack/entrypoints-html.js</code> ignores it.</p>"},{"location":"frontend/#javascript","title":"Javascript","text":"<p>All our JS files are run through Babel, allowing us to use modern JS syntax now, without having to worry whether our users' browsers support it.</p> <p>Webpack automatically minifies our JS when building the production bundle.</p>"},{"location":"frontend/#globals","title":"Globals","text":"<p>Because most of our JS stack was written well before modules were a thing, many files place variables in the global scope for other files to use. However in Webpack, unless a file explicitly places a variable under <code>window</code>, we have to expose each of those variables manually.</p> <p>This is done in <code>webpack/global-expose-rules.js</code>. Like above, over time we'll leverage imports to reduce the number of variables we have to expose to the global scope.</p>"},{"location":"frontend/#stylesheets","title":"Stylesheets","text":"<p>Our stylesheets are written in Sass, using its SCSS syntax (<code>.scss</code>).</p> <p>We use the MiniCssExtractPlugin to separate our CSS from our JS files.</p>"},{"location":"frontend/#postcss","title":"PostCSS","text":"<p>We use the postcss-loader to process our css files with postcss. Its configuration lives in <code>postcss.config.js</code>.</p> <p>When building a production bundle, cssnano minifies our CSS.</p>"},{"location":"frontend/#images","title":"Images","text":"<p>Images directly imported in JS files, or referenced in CSS files, are copied by Webpack into the build directory, after renaming and optimizing them.</p>"},{"location":"frontend/#in-django","title":"In Django","text":"<p>Aside from managing images directly imported in JS and CSS files, we also make use of Webpack to manage images used in Django itself, in Jinja2 templates and Python code.</p> <p>To do this, we make use of the CopyWebpackPlugin to copy images under certain paths into the build directory, after processing them through the asset pipeline.</p> <p>We then hook into the Webpack build process, in <code>webpack/asset-json-plugin.js</code>, to generate an original to build path mapping in the <code>dist/source-to-asset.json</code> file. We shorten the original path as explained below.</p> <p>Included images are those:</p> <ul> <li>under the Protocol icons directory: <code>node_modules/@mozilla-protocol/core/protocol/img/icons/</code>, shortened to <code>protocol/img/icons/</code></li> <li>under the static image directory for any Django app: <code>kitsune/*/static/**/img/</code>, shortened to <code>**/img/</code></li> </ul> <p>In Django, the <code>webpack_static</code> helper loads the mapping, and is used to get an output path for any image needed from those directories.</p>"},{"location":"frontend/#optimization","title":"Optimization","text":"<p>In the Webpack pipeline, PNGs are run through optipng, and SVGs are run through svgo.</p>"},{"location":"hacking_howto/","title":"Hacking howto","text":""},{"location":"hacking_howto/#development-setup","title":"Development Setup","text":""},{"location":"hacking_howto/#summary","title":"Summary","text":"<pre><code>This chapter helps you get an installation of Kitsune up and running.\n\nIf you have any problems getting Kitsune running, let us know. See :ref:`contact-us-chapter`.\n</code></pre>"},{"location":"hacking_howto/#getting-up-and-running","title":"Getting up and running","text":"<p>To get Kitsune running locally all you really need is to have Docker and Docker Compose installed, and follow the following steps.</p> <ol> <li> <p>Fork this repository &amp; clone it to your local machine.</p> <pre><code>git clone https://github.com/mozilla/kitsune.git\n</code></pre> </li> <li> <p>Create a <code>.env</code> file (if one doesn't already exist).</p> <pre><code>make .env\n</code></pre> </li> <li> <p>Pull base Kitsune Docker images, install node packages and build the Webpack bundle, and create your database.     On non-Apple silicon:</p> <pre><code>make init\n</code></pre> <p>On Apple silicon (M1, M2):</p> <pre><code>make init-mac\n</code></pre> <p>Then:</p> <pre><code>make build\n</code></pre> </li> <li> <p>Run Kitsune.</p> <pre><code>make run\n</code></pre> <p>This will produce a lot of output (mostly warnings at present). When you see the following the server will be ready:</p> <pre><code>web_1              | Starting development server at http://0.0.0.0:8000/\nweb_1              | Quit the server with CONTROL-C.\n</code></pre> <p>The running instance will be located at http://localhost:8000/ unless you specified otherwise, and the administrative control panel will be at http://localhost:8000/admin/.</p> </li> </ol> <p>Another way you might choose to run the app (step 3 above) is by getting a shell in the container and then manually running the Django dev server from there. This should make frequent restarts of the server a lot faster and easier if you need to do that:</p> <pre><code>make runshell\n./manage.py runserver 0.0.0.0:8000\n</code></pre> <p>The end result of this method should be the same as using <code>make run</code>, but will potentially aid in debugging and act much more like developing without Docker as you may be used to. You should use <code>make runshell</code> here instead of <code>make shell</code> as the latter does not bind port 8000 which you need to be able to load the site.</p> <p>Run <code>make help</code> to see other helpful commands.</p> <p>Then you can run the Webpack build with instant reloading through browser-sync:</p> <pre><code>npm start\n</code></pre> <p>The running instance in this case will be located at http://localhost:3000/.</p>"},{"location":"hacking_howto/#further-setup","title":"Further setup","text":""},{"location":"hacking_howto/#admin-interface","title":"Admin interface","text":"<p>After the above you can do some optional steps if you want to use the admin:</p> <ul> <li> <p>Enable the admin control panel</p> <pre><code>echo \"ENABLE_ADMIN=True\" &gt;&gt; .env\n</code></pre> </li> <li> <p>Create a superuser</p> <pre><code>docker-compose exec web ./manage.py createsuperuser\n</code></pre> </li> <li> <p>Create a profile for this user</p> <pre><code>$ ./manage.py shell_plus\nIn [1]: u = User.objects.get(username=\"superuser\")\nIn [2]: Profile(user=u).save()\n</code></pre> </li> <li> <p>Log in to the admin panel: http://localhost:8000/admin</p> </li> </ul>"},{"location":"hacking_howto/#enable-development-login","title":"Enable development login","text":"<p>If you need to log in as a normal user, add <code>ENABLE_DEV_LOGIN=True</code> to your <code>.env</code> file.</p> <p>You can create a normal user like so:</p> <pre><code>docker-compose exec web ./manage.py shell_plus\nIn [1]: u = User(username=\"foobar\")\nIn [2]: u.save()\nIn [3]: Profile(user=u).save()\n</code></pre> <p>You can then log in as that user by visiting: <code>http://localhost:8000/user/foobar/become</code></p>"},{"location":"hacking_howto/#install-sample-data","title":"Install Sample Data","text":"<pre><code>We include some sample data to get you started. You can install it by\nrunning this command::\n\n    docker-compose exec web ./manage.py generatedata\n</code></pre>"},{"location":"hacking_howto/#get-aaq-working","title":"Get AAQ working","text":"<ol> <li> <p>Add a product with a slug matching one of the product values in <code>kitsune/questions/config.py</code>.     You can do this through the admin interface at <code>/admin/products/product/add/</code>.</p> <p>For instance, with a <code>config.py</code> value like:</p> <pre><code>\"name\": _lazy(\"Firefox\"),\n\"product\": \"firefox\",\n</code></pre> <p>Create a product in the admin interface with its <code>slug</code> set to <code>firefox</code>.</p> </li> <li> <p>Add a topic matching a category from that product config,     and associate it with the product you just created.     You can do this through the admin interface at <code>/admin/products/topic/add/</code>.</p> <p>For instance, with a category with a <code>config.py</code> value like:</p> <pre><code>\"topic\": \"download-and-install\",\n</code></pre> <p>Create a topic in the admin interface with its <code>slug</code> set to <code>download-and-install</code> and its product set to the product you just created.</p> </li> <li> <p>Finally add an AAQ locale for that product.     You can do this through the admin interface at <code>/admin/questions/questionlocale/add/</code>.</p> </li> </ol>"},{"location":"hacking_howto/#get-search-working","title":"Get search working","text":"<p>First, make sure you have run the \"Install Sample Data\" step above, or have entered data yourself through the admin interface.</p> <ol> <li> <p>Enter into the web container</p> <pre><code>docker-compose exec web bash\n</code></pre> </li> <li> <p>Build the indicies</p> <pre><code>./manage.py es_init &amp;&amp; ./manage.py es_reindex\n</code></pre> </li> <li> <p>Now, exit from web's bash shell     <pre><code>exit\n</code></pre></p> </li> </ol> <p>Search</p> <p>If after running these commands, search doesn't seem to be working, make sure you're not running any ad-blocking extensions in your browser. They may be blocking the <code>analytics.js</code> script which search depends on.</p>"},{"location":"hacking_howto/#install-linting-tools","title":"Install linting tools","text":"<p>Kitsune uses pre-commit for linting. Install it globally, or in a venv, outside of the docker container with:</p> <pre><code>pip install pre-commit\n</code></pre> <p>Then set up its git pre-commit hook:</p> <pre><code>$ pre-commit install\n</code></pre> <p>After this, every time you commit, pre-commit will check your changes for style problems. To run it manually you can use the command:</p> <pre><code>$ pre-commit run\n</code></pre> <p>which will run the checks for only your changes, or if you want to run the lint checks for all files:</p> <pre><code>$ pre-commit run --all-files\n</code></pre> <p>For more details see the pre-commit docs.</p>"},{"location":"hacking_howto/#product-details-initialization","title":"Product Details Initialization","text":"<p>Note</p> <p>One of the packages Kitsune uses, <code>product_details</code>, needs to fetch JSON files containing historical Firefox version data and write them within its package directory. To set this up, run this command to do the initial fetch: <pre><code>    docker-compose exec web ./manage.py update_product_details\n</code></pre></p>"},{"location":"hacking_howto/#using-django-debug-toolbar","title":"Using Django Debug Toolbar","text":"<p>Django Debug Toolbar provides some very useful information when debugging various things in Django, especially slow running SQL queries.</p> <p>To enable it, ensure <code>DEBUG</code> and <code>USE_DEBUG_TOOLBAR</code> are enabled in <code>.env</code>:</p> <pre><code>DEBUG=True\nUSE_DEBUG_TOOLBAR=True\n</code></pre>"},{"location":"hacking_howto/#running-the-tests","title":"Running the tests","text":"<p>Running the test suite is easy:</p> <pre><code>./bin/run-unit-tests.sh\n</code></pre> <p>For more information, see the test documentation.</p>"},{"location":"k8s/","title":"K8s","text":""},{"location":"k8s/#sumo-kubernetes-support-guide","title":"SUMO Kubernetes Support Guide","text":""},{"location":"k8s/#links","title":"Links","text":"<p>High level:</p> <ul> <li>SUMO Infra home</li> <li>SUMO K8s deployment (obsolete)</li> <li>MozMEAO escalation path</li> <li>Architecture diagram<ul> <li>Source</li> </ul> </li> <li>SLA</li> <li>Incident Reports</li> </ul> <p>Tech details:</p> <ul> <li>SUMO K8s deployments/services/secrets templates</li> <li>SUMO AWS resource definitions</li> </ul>"},{"location":"k8s/#k8s-commands","title":"K8s commands","text":"<p>Most of the examples use <code>sumo-prod</code> as an example namespace. SUMO dev/stage/prod run in the <code>sumo-dev</code>/<code>sumo-stage</code>/<code>sumo-prod</code> namespaces respectively.</p>"},{"location":"k8s/#general","title":"General","text":"<p>Most examples are using the <code>kubectl get ...</code> subcommand. If you'd prefer output that's more readable, you can substitute the <code>get</code> subcommand with <code>describe</code>:</p> <pre><code>kubectl -n sumo-prod describe pod sumo-prod-web-76b74db69-dvxbh\n</code></pre> <p>Listing resources is easier with the <code>get</code> subcommand.</p> <p>To see all SUMO pods currently running:</p> <pre><code>kubectl -n sumo-prod get pods\n</code></pre> <p>To see all pods running and the K8s nodes they are assigned to:</p> <pre><code>kubectl -n sumo-prod get pods -o wide\n</code></pre> <p>To show yaml for a single pod:</p> <pre><code>kubectl -n sumo-prod get pod sumo-prod-web-76b74db69-dvxbh -o yaml\n</code></pre> <p>To show all deployments:</p> <pre><code> kubectl -n sumo-prod get deployments\n\nNAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nsumo-prod-celery   3         3         3            3           330d\nsumo-prod-cron     0         0         0            0           330d\nsumo-prod-web      50        50        50           50          331d\n</code></pre> <p>To show yaml for a single deployment:</p> <pre><code> kubectl -n sumo-prod get deployment sumo-prod-web -o yaml\n</code></pre> <p>Run a bash shell on a SUMO pod:</p> <pre><code>kubectl -n sumo-prod exec -it sumo-prod-web-76b74db69-xbfgj bash\n</code></pre> <p>Scaling a deployment:</p> <pre><code>kubectl -n sumo-prod scale --replicas=60 deployment/sumo-prod-web\n</code></pre> <p>Check rolling update status:</p> <pre><code>kubectl -n sumo-prod rollout status deployment/sumo-prod-web\n</code></pre>"},{"location":"k8s/#working-with-k8s-command-output","title":"Working with K8s command output","text":"<p>Filtering pods based on a label:</p> <pre><code>kubectl -n sumo-prod -l type=web get pods\n</code></pre> <p>Getting a list of pods:</p> <pre><code>kubectl -n sumo-prod -l type=web get pods | tail -n +2 | cut -d\" \" -f 1\n</code></pre> <p>Structured output:</p> <p>See the jsonpath guide here</p> <pre><code>kubectl -n sumo-prod get pods -o=jsonpath='{.items[0].metadata.name}'\n</code></pre> <p>Processing K8s command json output with jq:</p> <p>jsonpath may be more portable</p> <pre><code>kubectl -n sumo-prod get pods -o json | jq -r .items[].metadata.name\n</code></pre>"},{"location":"k8s/#k8s-services","title":"K8s Services","text":"<p>List SUMO services:</p> <pre><code>kubectl -n sumo-prod get services\nNAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)         AGE\nsumo-nodeport   NodePort   100.71.222.28   &lt;none&gt;        443:30139/TCP   341d\n</code></pre>"},{"location":"k8s/#secrets","title":"Secrets","text":"<p>K8s secrets docs</p> <p>Secret values are base64 encoded when viewed in K8s output. Once setup as an environment variable or mounted file in a pod, the values are base64 decoded automatically.</p> <p>Kitsune uses secrets specified as environment variables in a deployment spec:</p> <ul> <li>example</li> </ul> <p>To list secrets:</p> <pre><code>kubectl -n sumo-prod get secrets\n</code></pre> <p>To view a secret w/ base64-encoded values:</p> <pre><code>kubectl -n sumo-prod get secret sumo-secrets-prod -o yaml\n</code></pre> <p>To view a secret with decoded values (aka \"human readable\"):</p> <p>This example uses the ksv utility</p> <pre><code>kubectl -n sumo-prod get secret sumo-secrets-prod -o yaml | ksv\n</code></pre> <p>To encode a secret value:</p> <pre><code>echo -n \"somevalue\" | base64\n</code></pre> <p>The <code>-n</code> flag strips the newline before base64 encoding. Values must be specified without newlines, the <code>base64</code> command on Linux can take a <code>-w 0</code> parameter that outputs without newlines. The <code>base64</code> command in Macos Sierra seems to output encoded values without newlines.</p> <p>Updating secrets:</p> <pre><code>kubectl -n sumo-prod apply -f ./some-secret.yaml\n</code></pre>"},{"location":"k8s/#monitoring","title":"Monitoring","text":""},{"location":"k8s/#new-relic","title":"New Relic","text":"<ul> <li> <p>Primary region</p> <ul> <li><code>sumo-prod-oregon</code></li> </ul> </li> <li> <p>Failover region</p> <ul> <li><code>sumo-prod-frankfurt</code></li> </ul> </li> </ul>"},{"location":"k8s/#papertrail","title":"Papertrail","text":"<p>All pod output is logged to Papertrail.</p> <ul> <li>Oregon</li> <li>Frankfurt</li> </ul>"},{"location":"k8s/#elasticco","title":"elastic.co","text":"<p>Our hosted Elasticsearch cluster is in the <code>us-west-2</code> region of AWS. Elastic.co hosting status can be found on this page.</p>"},{"location":"k8s/#operations","title":"Operations","text":""},{"location":"k8s/#cronjobs","title":"Cronjobs","text":"<p>The <code>sumo-prod-cron</code> deployment is a self-contained Python cron system that runs in both Primary and Failover clusters.</p> <pre><code> # Oregon\nkubectl -n sumo-prod get deployments\nNAME               DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE\nsumo-prod-celery   3         3         3            3           330d\nsumo-prod-cron     1         1         1            1           330d\nsumo-prod-web      25        25        25           25          331d\n</code></pre>"},{"location":"k8s/#manually-addingremoving-k8s-oregonfrankfurt-cluster-nodes","title":"Manually adding/removing K8s Oregon/Frankfurt cluster nodes","text":"<p>If you are modifying the Frankfurt cluster, replace instances of <code>oregon-*</code> below with <code>frankfurt</code>.</p> <ol> <li>login to the AWS console</li> <li>ensure you are in the <code>Oregon</code> region</li> <li>search for and select the <code>EC2</code> service in the AWS console</li> <li>select <code>Auto Scaling Groups</code> from the navigation on the left side of the page</li> <li>click on the <code>nodes.k8s.us-west-2a.sumo.mozit.cloud</code> or <code>nodes.k8s.us-west-2b.sumo.mozit.cloud</code> row to select it</li> <li>from the <code>Actions</code> menu (close to the top of the page), click <code>Edit</code></li> <li>the <code>Details</code> tab for the ASG should appear, set the appropriate <code>Min</code>, <code>Desired</code> and <code>Max</code> values.<ol> <li>it's probably good to set <code>Min</code> and <code>Desired</code> to the same value in case the cluster autoscaler decides to scale down the cluster smaller than the <code>Min</code>.</li> </ol> </li> <li>click <code>Save</code></li> <li>if you click on <code>Instances</code> from the navigation on the left side of the page, you can see the new instances that are starting/stopping.</li> <li>you can see when the nodes join the K8s cluster with the following command:</li> </ol> <pre><code>watch 'kubectl get nodes | tail -n +2 | grep -v main | wc -l'\n</code></pre> <p>The number that is displayed should eventually match your ASG <code>Desired</code> value. Note this value only includes K8s workers.</p>"},{"location":"k8s/#manually-blocking-an-ip-address","title":"Manually Blocking an IP address","text":"<ol> <li>login to the AWS console</li> <li>ensure you are in the <code>Oregon</code> region</li> <li>search for and select the <code>VPC</code> service in the AWS console</li> <li>select <code>Network ACLs</code> from the navigation on the left side of the page</li> <li>select the row containing the <code>Oregon</code> VPC</li> <li>click on the <code>Inbound Rules</code> tab</li> <li>click <code>Edit</code></li> <li>click <code>Add another rule</code></li> <li>for <code>Rule#</code>, select a value &lt; 100 and &gt; 0</li> <li>for <code>Type</code>, select <code>All Traffic</code></li> <li>for <code>Source</code>, enter the IP address in CIDR format. To block a single IP, append <code>/32</code> to the IP address.<ol> <li>example: <code>196.52.2.54/32</code></li> </ol> </li> <li>for <code>Allow / Deny</code>, select <code>DENY</code></li> <li>click <code>Save</code></li> </ol> <p>There are limits that apply to using VPC ACLs documented here.</p>"},{"location":"k8s/#manually-initiating-cluster-failover","title":"Manually Initiating Cluster failover","text":"<p>Note: Route 53 will provide automated cluster failover, these docs cover things to consider if there is a catastrophic failure in Oregon and Frankfurt must be promoted to primary rather than a read-only failover.</p> <ul> <li>verify the Frankfurt read replica<ul> <li><code>eu-central-1</code> (Frankfurt) has a read-replica of the SUMO production database</li> <li>the replica is currently a <code>db.m4.xlarge</code>, while the prod DB is <code>db.m4.4xlarge</code><ul> <li>this may be ok in maintenance mode, but if you are going to enable write traffic, the instance type must be scaled up.<ul> <li>SRE's performed a manual instance type change on the Frankfurt read-replica, and it took ~10 minutes to change from a <code>db.t2.medium</code> to a <code>db.m4.xlarge</code>.</li> </ul> </li> </ul> </li> <li>although we have alerting in place to notify the SRE team in the event of a replication error, it's a good idea to check the replication status on the RDS details page for the <code>sumo</code> MySQL instance.<ul> <li>specifically, check the <code>DB Instance Status</code>, <code>Read Replica Source</code>, <code>Replication State</code>, and <code>Replication Error</code> values.</li> </ul> </li> <li>decide if promoting the read-replica to a main is appropriate.<ul> <li>it's preferrable to have a multi-AZ RDS instance, as we can take snapshots against the failover instance (RDS does this by default in a multi-AZ setup).</li> <li>if data is written to a promoted instance, and failover back to the us-west-2 clusters is desirable, a full DB backup and restore in us-west-2 is required.</li> <li>the replica is automatically rebooted before being promoted to a full instance.</li> </ul> </li> </ul> </li> <li>ensure image versions are up to date</li> <li>Most MySQL changes should already be replicated to the read-replica, however, if you're reading this, chances are things are broken. Ensure that the DB schema is correct for the iamges you're deploying.</li> <li> <p>scale cluster and pods</p> <ul> <li>the prod deployments yaml contains the correct number of replicas, but here are some safe values to use in an emergency:</li> </ul> </li> <li> <p>DNS</p> <ul> <li>point the <code>prod-tp.sumo.mozit.cloud</code> traffic policy at the Frankfurt ELB</li> </ul> </li> </ul>"},{"location":"localization/","title":"Localization","text":"<p>Kitsune is localized with gettext. User-facing strings in the code or templates need to be marked for gettext localization.</p> <p>We use Pontoon to provide an easy interface to localizing these files. Localizers are also free to download the PO files and use whatever tool they are comfortable with.</p>"},{"location":"localization/#making-strings-localizable","title":"Making Strings Localizable","text":"<p>Making strings in templates localizable is exceptionally easy. Making strings in Python localizable is a little more complicated. The short answer, though, is just wrap the string in <code>_()</code>.</p>"},{"location":"localization/#interpolation","title":"Interpolation","text":"<p>A string is often a combination of a fixed string and something changing, for example, <code>Welcome, James</code> is a combination of the fixed part <code>Welcome,</code>, and the changing part <code>James</code>. The naive solution is to localize the first part and the follow it with the name:</p> <pre><code>_('Welcome, ') + username\n</code></pre> <p>This is wrong!</p> <p>In some locales, the word order may be different. Use Python string formatting to interpolate the changing part into the string:</p> <pre><code>_('Welcome, {name}').format(name=username)\n</code></pre> <p>Python gives you a lot of ways to interpolate strings. The best way is to use Py3k formatting and kwargs. That's the clearest for localizers.</p> <p>The worst way is to use <code>%(label)s</code>, as localizers seem to have all manner of trouble with it. Options like <code>%s</code> and <code>{0}</code> are somewhere in the middle, and generally OK if it's clear from context what they will be.</p>"},{"location":"localization/#localization-comments","title":"Localization Comments","text":"<p>Sometimes, it can help localizers to describe where a string comes from, particularly if it can be difficult to find in the interface, or is not very self-descriptive (e.g. very short strings). If you immediately precede the string with a comment that starts <code>L10n:</code>, the comment will be added to the PO file, and visible to localizers.</p> <p>Example:</p> <pre><code>rev_data.append({\n            'x': 1000 * int(time.mktime(rdate.timetuple())),\n            # L10n: 'R' is the first letter of \"Revision\".\n            'title': _('R', 'revision_heading'),\n            'text': str(_('Revision %s')) % rev.created\n            #'url': 'http://www.google.com/'  # Not supported yet\n        })\n</code></pre>"},{"location":"localization/#adding-context-with-msgctxt","title":"Adding Context with msgctxt","text":"<p>Strings may be the same in English, but different in other languages. English, for example, has no grammatical gender, and sometimes the noun and verb forms of a word are identical.</p> <p>To make it possible to localize these correctly, we can add \"context\" (known in gettext as \"msgctxt\") to differentiate two otherwise identical strings.</p> <p>For example, the string \"Search\" may be a noun or a verb in English. In a heading, it may be considered a noun, but on a button, it may be a verb. It's appropriate to add a context (like \"button\") to one of them.</p> <p>Generally, we should only add context if we are sure the strings aren't used in the same way, or if localizers ask us to.</p> <p>Example:</p> <pre><code>from tower import ugettext as _\n\n...\n\nfoo = _('Search', context='text for the search button on the form')\n</code></pre>"},{"location":"localization/#plurals","title":"Plurals","text":"<p>\"You have 1 new messages\" grates on discerning ears. Fortunately, gettext gives us a way to fix that in English and other locales, the <code>ngettext</code> function:</p> <pre><code>ngettext('singular', 'plural', count)\n</code></pre> <p>A more realistic example might be:</p> <pre><code>ngettext('Found {count} result.',\n         'Found {count} results',\n         len(results)).format(count=len(results))\n</code></pre> <p>This method takes three arguments because English only needs three, i.e., zero is considered \"plural\" for English. Other locales may have different plural rules, and require different phrases for, say 0, 1, 2-3, 4-10, &gt;10. That's absolutely fine, and gettext makes it possible.</p>"},{"location":"localization/#strings-in-html-templates","title":"Strings in HTML Templates","text":"<p>When putting new text into a template, all you need to do is wrap it in a <code>_()</code> call:</p> <pre><code>&lt;h1&gt;{{ _('Heading') }}&lt;/h1&gt;\n</code></pre> <p>Adding context is easy, too:</p> <pre><code>&lt;h1&gt;{{ _('Heading', 'context') }}&lt;/h1&gt;\n</code></pre> <p>L10n comments need to be Jinja2 comments:</p> <pre><code>{# L10n: Describes this heading #}\n&lt;h1&gt;{{ _('Heading') }}&lt;/h1&gt;\n</code></pre> <p>Note that Jinja2 escapes all content output through <code>{{ }}</code> by default. To put HTML in a string, you'll need to add the <code>|safe</code> filter:</p> <pre><code>&lt;h1&gt;{{ _('Firefox &lt;span&gt;Help&lt;/span&gt;')|safe }}&lt;/h1&gt;\n</code></pre> <p>To interpolate, you should use one of two Jinja2 filters: <code>|f()</code> or, in some cases, <code>|fe()</code>. <code>|f()</code> has exactly the same arguments as <code>u''.format()</code>:</p> <pre><code>{{ _('Welcome, {name}!')|f(name=request.user.username) }}\n</code></pre> <p>The <code>|fe()</code> is exactly like the <code>|f()</code> filter, but escapes its arguments before interpolating, then returns a \"safe\" object. Use it when the localized string contains HTML:</p> <pre><code>{{ _('Found &lt;strong&gt;{0}&lt;/strong&gt; results.')|fe(num_results) }}\n</code></pre> <p>Note that you do not need to use <code>|safe</code> with <code>|fe()</code>. Also note that while it may look similar, the following is not safe:</p> <pre><code>{{ _('Found &lt;strong&gt;{0}&lt;/strong&gt; results.')|f(num_results)|safe }}\n</code></pre> <p>The <code>ngettext</code> function is also available:</p> <pre><code>{{ ngettext('Found {0} result.',\n            'Found {0} results.',\n            num_results)|f(num_results) }}\n</code></pre>"},{"location":"localization/#using-trans-blocks-for-long-strings","title":"Using <code>{% trans %}</code> Blocks for Long Strings","text":"<p>When a string is very long, i.e. long enough to make Github scroll sideways, it should be line-broken and put in a <code>{% trans %}</code> block. <code>{% trans %}</code> blocks work like other block-level tags in Jinja2, except they cannot have other tags, except strings, inside them.</p> <p>The only thing that should be inside a <code>{% trans %}</code> block is printing a string with <code>{{ string }}</code>. These are defined in the opening <code>{% trans %}</code> tag:</p> <pre><code>{% trans user=request.user.username %}\n    Thanks for registering, {{ user }}! We're so...\n    hope that you'll...\n{% endtrans %}\n</code></pre> <p>You can also provide comments:</p> <pre><code>{# L10n: User is a username #}\n{% trans user=request.user.username %}\n    Thanks for registering, {{ user }}! We're so...\n    hope that you'll...\n{% endtrans %}\n</code></pre> <p>When a block contains HTML with attributes, those which don't need to be localized should be passed as arguments. This ensures strings won't need to be re-localized if those attributes change:</p> <pre><code>{% trans url=\"http://example.com\" %}\n    Please visit &lt;a href=\"{{ url }}\" title=\"External Site\"&gt;our FAQ&lt;/a&gt; for more information.\n{% endtrans %}\n</code></pre>"},{"location":"localization/#strings-in-python","title":"Strings in Python","text":"<p>String location</p> <p>Whenever you are adding a string in Python, ask yourself if it really needs to be there, or if it should be in the template. Keep logic and presentation separate!</p> <p>Strings in Python are more complex for two reasons:</p> <ol> <li>We need to make sure we're always using Unicode strings and the     Unicode-friendly versions of the functions.</li> <li>If you use the <code>ugettext</code> function in the wrong place, the string     may end up in the wrong locale!</li> </ol> <p>Here's how you might localize a string in a view:</p> <pre><code>from tower import ugettext as _\n\ndef my_view(request):\n    if request.user.is_superuser:\n        msg = _(u'Oh hi, staff!')\n    else:\n        msg = _(u'You are not staff!')\n</code></pre> <p>Interpolation is done through normal Python string formatting:</p> <pre><code>msg = _(u'Oh, hi, {user}').format(user=request.user.username)\n</code></pre> <p><code>ugettext</code> supports context, too:</p> <pre><code>msg = _('Search', 'context')\n</code></pre> <p>L10n comments are normal one-line Python comments:</p> <pre><code># L10n: A message to users.\nmsg = _(u'Oh, hi there!')\n</code></pre> <p>If you need to use plurals, import the function <code>ungettext</code> from Tower:</p> <pre><code>from tower import ungettext, ugettext as _\n\nn = len(results)\nmsg = ungettext('Found {0} result', 'Found {0} results', n).format(n)\n</code></pre>"},{"location":"localization/#lazily-translated-strings","title":"Lazily Translated Strings","text":"<p>You can use <code>ugettext</code> or <code>ungettext</code> only in views or functions called from views. If the function will be evaluated when the module is loaded, then the string may end up in English or the locale of the last request! (We're tracking down that issue.)</p> <p>Examples include strings in module-level code, arguments to functions in class definitions, strings in functions called from outside the context of a view. To localize these strings, you need to use the <code>_lazy</code> versions of the above methods, <code>ugettext_lazy</code> and <code>ungettext_lazy</code>. The result doesn't get translated until it is evaluated as a string, for example by being output or passed to <code>str()</code>:</p> <pre><code>from tower import ugettext_lazy as _lazy\n\nPAGE_TITLE = _lazy(u'Page Title')\n</code></pre> <p><code>ugettext_lazy</code> also supports context.</p> <p>It is very important to pass Unicode objects to the <code>_lazy</code> versions of these functions. Failure to do so results in significant issues when they are evaluated as strings.</p> <p>If you need to work with a lazily-translated string, you'll first need to convert it to a <code>str</code> object:</p> <pre><code>from tower import ugettext_lazy as _lazy\n\nWELCOME = _lazy(u'Welcome, %s')\n\ndef my_view(request):\n    # Fails:\n    WELCOME % request.user.username\n\n    # Works:\n    str(WELCOME) % request.user.username\n</code></pre>"},{"location":"localization/#strings-in-the-database","title":"Strings in the Database","text":"<p>There is some user generated content that needs to be localizable. For example, karma titles can be created in the admin site and need to be localized when displayed to users. A django management command is used for this. The first step to making a model's field localizable is adding it to <code>DB_LOCALIZE</code> in <code>settings.py</code>:</p> <pre><code>DB_LOCALIZE = {\n    'karma': {\n        'Title': {\n            'attrs': ['name'],\n            'comments': ['This is a karma title.'],\n        }\n    },\n    'appname': {\n        'ModelName': {\n            'attrs': ['field_name'],\n            'comments': ['Optional comments for localizers.'],\n        }\n    }\n}\n</code></pre> <p>Then, all you need to do is run the <code>extract_db</code> management command:</p> <pre><code>python manage.py extract_db\n</code></pre> <p>Be sure to have a recent database from production when running the command.</p> <p>By default, this will write all the strings to [kitsune/sumo/db_strings.py]{.title-ref} and they will get picked up during the normal string extraction (see below).</p>"},{"location":"localization/#strings-in-email-templates","title":"Strings in Email Templates","text":"<p>Currently, email templates are text-based and not in HTML. Because of that you should use this style guide:</p> <ol> <li> <p>The entire email should be wrapped in autoescape. e.g.</p> <pre><code>{% autoescape false %}\n{% trans %}\nThe entire email should be wrapped in autoescape.\n{% endtrans %}\n\n\n...\n{% endautoescape %}\n</code></pre> </li> <li> <p>After an <code>{% endtrans %}</code>, you need two blank lines (three carriage     returns). The first is eaten by the tag. The other two show up in     the email. e.g.</p> <pre><code>{% trans %}\nTo confirm your subscription, stand up, put your hands on\nyour hips and do the hokey pokey.\n{% endtrans %}\n\n\n{{ _('Thanks!') }}\n</code></pre> <p>Produces this:</p> <pre><code>To confirm your subscription, stand up, put your hands on\nyour hips and do the hokey pokey.\n\nThanks!\n</code></pre> </li> <li> <p>Putting in line breaks in a <code>trans</code> block doesn't have an effect     since <code>trans</code> blocks get gettexted and whitespace is collapsed.</p> </li> </ol>"},{"location":"localization/#testing-localized-strings","title":"Testing localized strings","text":"<p>When we add strings that need to be localized, it can take a couple of weeks for us to get translations of those localized strings. This makes it difficult to find localization issues.</p> <p>Enter Dennis.</p> <p>Run:</p> <pre><code>$ ./scripts/test_locales.sh\n</code></pre> <p>It'll extract all the strings, create a <code>.pot</code> file, then create a Pirate translation of all strings. The Pirate strings are available in the xx locale. After running the <code>test_locales.sh</code> script, you can access the xx locale with:</p> <p>http://localhost:8000/xx/</p> <p>Strings in the Pirate translation have the following properties:</p> <ol> <li>they are longer than the English string: helps us find layout and     wrapping issues</li> <li>they have at least one unicode character: helps us find unicode     issues</li> <li>they are easily discernable from the English versions: helps us find     strings that aren't translated</li> </ol> <p>::: note ::: title Note :::</p> <p>The xx locale is only available on your local machine. It is not available on -dev, -stage, or -prod. :::</p>"},{"location":"localization/#linting-localized-strings","title":"Linting localized strings","text":"<p>You can lint localized strings for warnings and errors:</p> <pre><code>$ dennis-cmd lint locale/\n</code></pre> <p>Or just errors:</p> <pre><code>$ dennis-cmd lint --errorsonly locale/\n</code></pre> <p>You can see help text:</p> <pre><code>$ dennis-cmd\n</code></pre>"},{"location":"localization/#getting-the-localizations-getting-localizations","title":"Getting the Localizations {#getting-localizations}","text":"<p>Localizations are not stored in this repository, but are in a separate Git repo:</p> <p>https://github.com/mozilla-l10n/sumo-l10n</p> <p>You don't need the localization files for general development. However, if you need them for something, they're pretty easy to get:</p> <pre><code>$ cd kitsune\n$ git clone https://github.com/mozilla-l10n/sumo-l10n locale\n</code></pre>"},{"location":"localization/#updating-the-localizations","title":"Updating the Localizations","text":"<p>When strings are added or updated, we need to update the templates and PO files for localizers. Updating strings is pretty easy. Check out the localizations as above, then:</p> <pre><code>$ python manage.py extract\n$ python manage.py merge\n</code></pre> <p>Congratulations! You've now updated the POT and PO files.</p> <p>Sometimes this can leave a bunch of garbage files with <code>.po~</code> extensions. You should delete these, never commit them:</p> <pre><code>$ find . -name \"*.po~\" -delete\n</code></pre>"},{"location":"localization/#adding-a-new-locale","title":"Adding a New Locale","text":"<p>Say you wanted to add <code>fa-IR</code>:</p> <pre><code>$ mkdir -p locale/fa-IR/LC_MESSAGES\n$ python manage.py merge\n</code></pre> <p>Then add 'fa-IR' to SUMO_LANGUAGES in settings.py and make sure there is an entry in lib/languages.json (if not, add it).</p> <p>And finally, add a migration with:</p> <pre><code>INSERT INTO `wiki_locale` (`locale`) VALUES ('fa-IR');\n</code></pre> <p>Done!</p>"},{"location":"localization/#compiling-mo-files","title":"Compiling MO Files","text":"<p>gettext is so fast for localization because it doesn't parse text files, it reads a binary format. You can easily compile that binary file from the PO files in the repository.</p> <p>We don't store MO files in the repository because they need to change every time the corresponding PO file changes, so it's silly and not worth it. They are ignored by <code>.gitignore</code>, but please make sure you don't forcibly add them to the repository.</p> <p>There is a shell script to compile the MO files for you:</p> <pre><code>$ ./locale/compile-mo.sh locale\n</code></pre> <p>Done!</p>"},{"location":"localization/#why-arent-localized-strings-getting-updated-on-prod","title":"Why aren't localized strings getting updated on prod?","text":"<p>We use Dennis to <code>lint .po files for errors&lt;localization:Linting localized strings&gt;</code>{.interpreted-text role=\"ref\"} that cause HTTP 500 errors in production. Things like malformed variables, variables in the translated string that aren't in the original and that sort of thing.</p> <p>For example, this would cause the site to break:</p> <pre><code>#: kitsune/questions/templates/questions/includes/answer.html:19\nmsgid \"{num} answers\"\nmsgstr \"{0} antwoorden\"\n</code></pre> <p>In this example, the <code>{0}</code> is wrong.</p>"},{"location":"localization/#reporting-errors-in-po-files","title":"Reporting errors in .po files","text":"<p>When we do a deployment to production, we dump all the Dennis output into:</p> <p>https://support.mozilla.org/static/postatus.txt</p> <p>We need to check that periodically and report the errors.</p> <p>If there are errors in those files, we need to open up a bug in Mozilla Localizations -&gt; locale code with the specifics.</p> <p>Product:</p> <p>Mozilla Localizations</p> <p>Component:</p> <p>The locale code for the language in question</p> <p>Bug summary:</p> <p>Use the error line</p> <p>Bug description template:</p> <pre><code>We found errors in the translated strings for Mozilla Support\n&lt;https://support.mozilla.org/&gt;. The errors are as follows:\n\n\n&lt;paste errors here&gt;\n\n\nUntil these errors are fixed, we can't deploy updates to the\nstrings for this locale to production.\n\nMozilla Support strings can be fixed in the Support Mozilla project\nin Pontoon &lt;https://pontoon.mozilla.org/projects/sumo/&gt;.\n\nIf you have any questions, let us know.\n</code></pre>"},{"location":"notes/","title":"Other Notes","text":"<p>::: warning ::: title Warning :::</p> <p>This section of documentation may be outdated. :::</p>"},{"location":"notes/#questions","title":"Questions","text":""},{"location":"notes/#memcached","title":"memcached","text":"<p>::: note ::: title Note :::</p> <p>This should probably be somewhere else, but the easy way to flush your cache is something like this:</p> <pre><code>echo \"flush_all\" | nc localhost 11211\n</code></pre> <p>Assuming you have memcache configured to listen to 11211. :::</p>"},{"location":"patching/","title":"Patching Kitsune","text":"<p>Submitting a patch to Kitsune is easy! (Fair warning: writing the patch may not be ;)</p> <p>We use pull requests to manage patches and code reviews, and Bugzilla to handle actual bug tracking.</p> <p>Because of our infrastructure and how we do deployments, we've developed a fairly straight-forward workflow in git for submitting patches. This is outlined below.</p> <p>You should run the tests before submitting a pull request. You can find help for getting set up in the installation docs and help for running tests in the testing docs.</p> <p>If you ever find yourself stuck, contact us. We 're happy to help!</p> <p>You 'll need a Github account and a Bugzilla account.</p>"},{"location":"patching/#the-quick-and-dirty","title":"The Quick and Dirty","text":"<p>Very quick, very little explanation. Those with strong git fu may already see some shortcuts. Use them!</p> <p>First, clone your fork, and then point the main branch to Mozilla's fork. Assuming your Github account is <code>foobar</code> and you've already forked Kitsune:</p> <pre><code>git clone https://github.com/foobar/kitsune\ncd kitsune\ngit remote add mozilla https://github.com/mozilla/kitsune.git\ngit fetch mozilla\ngit checkout -t mozilla/main -B main\n</code></pre> <p>If you haven't set up your local git user, please do before committing any code for Kitsune. This way you can take credit for your work:</p> <pre><code>git config user.email your@github.email\ngit config user.name \"Your Name\"\n</code></pre> <p>You should only need to do that once. Here's the bit to do every time:</p> <pre><code>git checkout main\ngit reset --hard mozilla/main\ngit checkout -b my-feature-123456\n\n# Make a change and commit it.\n$EDITOR path/to/file.py\ngit add path/to/file.py\ngit commit -m \"[Bug 123456] Fooing and the Barring.\"\ngit push --set-upstream origin my-feature\n\n# Open a pull request, get review.\n# Respond to feedback:\n$EDITOR path/to/file.py\ngit add path/to/file.py\ngit commit -m \"Feedback from Barfoo\"\ngit push\n</code></pre> <p>Eventually you will get an <code>r+</code>. If you have commit access, now you can go ahead and merge your branch. If you do not have commit access the next part will be done by someone who does.</p> <p>There are two options. The first is to press the Big Green Button in GitHub PRs that says \"Merge pull Request\". If you would prefer to do it manually or if there are merge conflicts, you can do this:</p> <pre><code># r+! Merge\ngit checkout main\ngit fetch mozilla\ngit reset --hard mozilla/main\ngit merge --no-ff my-feature-123456\ngit push mozilla main  # Bots will alert everyone!\ngit push origin main  # Optional but nice.\n</code></pre> <p>After the pull request is closed:</p> <pre><code>git push origin :my-feature  # Delete the remote branch. Nice to others.\ngit branch -D my-feature # Delete the local branch, if you're done.\n</code></pre>"},{"location":"patching/#the-details","title":"The Details","text":"<p>This is the process in more detail, for a relatively small change that will only need one commit and doesn not need any special treatment, like landing on special branches.</p>"},{"location":"patching/#fork-and-clone-kitsune","title":"Fork and Clone Kitsune","text":"<p>On Github, hit the Fork button. You will want to clone your fork of the project:</p> <p><code>bash git clone git@github.com:&lt;yourname&gt;/kitsune.git</code></p> <p>To help keep up to date, you should add <code>mozilla/kitsune</code> as a remote:</p> <pre><code>    cd kitsune\n    git remote add mozilla https://github.com/mozilla/kitsune.git\n</code></pre> <p>You should avoid changing your <code>main</code> branch, it should track <code>mozilla/main</code>. This can help:</p> <pre><code>    git fetch mozilla\n    # Update your main branch to track Mozilla's main branch instead.\n    git checkout -B main -t mozilla/main # Update your main branch to\n</code></pre> <p>If you haven't set up your local git user, please do before committing any code for Kitsune. This way you can take credit for your work:</p> <pre><code>    git config user.email your@github.email\n    git config user.name \"Your Name\"\n</code></pre> <p>The correct way to keep your local main up to date is:</p> <pre><code>    git checkout main\n    git fetch mozilla\n    git reset --hard mozilla/main\n</code></pre> <p>This will forcibly move your local main branch to whatever is on the Mozilla main branch, destroying anything you have committed that wasn't pushed. Remember to always work on a branch that is not main!</p>"},{"location":"patching/#find-a-bug","title":"Find a Bug","text":"<p>Step one is to make sure there's a bug in Bugzilla. Obvious \"bugs\" just need a Bugzilla bug to track the work for all the involved teams. There are a number of open bugs if you want to try your hand at fixing something!</p> <p>New features or changes to features need bugs to build a consensus of developers, support team members and community members, before we decide to make the change. If you want to change something like this, be sure to file the bug and get a consensus first. We'd hate to have you spend time on a patch we cannot take.</p>"},{"location":"patching/#take-the-bug","title":"Take the Bug","text":"<p>To make sure no one else is working on the bug at the same time, assign it to yourself in Bugzilla. If you have the proper permissions there's an easy \"take\" link next to the Assignee field. Ask in Matrix for details.</p> <p>You can assign bugs to yourself even if you aren't going to immediately work on them (though make sure you will get to them sooner rather than later). Once you are actively working on a bug, set the bug to the <code>ASSIGNED</code> state.</p>"},{"location":"patching/#fix-the-bug-on-a-branch","title":"Fix the Bug on a Branch","text":"<p>Note</p> <p>This describes the process for fixing a relatively small bug in a single-commit. Large features may differ.</p> <p>All bug fixes, changes, new features, etc, should be done on a \"feature branch\", which just means \"any branch besides <code>main</code>.\" You should make sure your local <code>main</code> branch is up to date (see above) before starting a new feature branch. Your feature branch should include the bug number in the branch name, if applicable.</p> <pre><code>    git checkout main\n    git fetch mozilla\n    git reset --hard upstream/main  # Update local main.\n    git checkout -b my-feature-branch-123456  # Some logical name.\n</code></pre> <p>Now you're on a feature branch, go ahead and make your changes. Assuming you haven't added any new files, you can do:</p> <pre><code>    git commit -a -m \"[Bug 123456] Fix the foo and the bar.\"\n</code></pre> <p>If you did add new files, you will have to <code>git add</code> them before committing.</p>"},{"location":"patching/#open-a-pull-request","title":"Open a Pull Request","text":"<p>Once you have the bug fixed locally, you will need to push the changes up to Github so you can open a pull request.</p> <pre><code>    git push --set-upstream origin my-feature-branch\n</code></pre> <p>Then, in your browser, navigate to <code>https://github.com/&lt;yourname&gt;/kitsune/compare/my-feature-branch</code> and hit the Pull Request button. If the commit message is clear, the form should be filled out enough for you to submit it right away.</p> <p>We add an <code>r?</code> in the pull request message indicating that this pull request is ready to go and is looking for someone to review it.</p> <p>Othertimes you may want to open a pull request early that isn't quite ready to merge. This is a great way to share the work that you are doing, and get early feedback. Make it clear that your PR isn't ready by putting <code>[WIP]</code> in the title. Also make sure to say when it is ready! The best way to do this is to remove <code>[WIP]</code> from the title and make a comment asking for <code>r?</code>.</p>"},{"location":"patching/#respond-to-review","title":"Respond to Review","text":"<p>It's very rare that pull requests will be checked in immediately. Most of the time they will go through one or more rounds of code review and clean-up.</p> <p>Code review is usually comments made on the pull request or commits in Github, asking for specific changes to be made. If the requested change isn't clear, or you disagree with it, feel free to ask questions inline. Isn't Github's line-by-line commenting great?</p> <p>Assuming a few small changes need to be made, make the changes locally on the feature branch, then put them in a new commit. This makes it easier from reviewers. For example, if Erik reviewed the pull request and asked for some fixes, you might do this:</p> <pre><code>git checkout my-feature-branch\n# Make the changes.\ngit commit -a -m \"Feedback from Erik.\"\ngit push origin my-feature-branch\n</code></pre> <p>Github will automatically add the new commit to the pull request, so we'll see it. Leaving it in a separate commit at this stage helps the reviewer see what changes you've made.</p> <p>There may be more than one round of feedback, especially for complex bugs. The process is exactly the same after each round: make the changes, add them in yet another new commit, push the changes.</p> <p>There are also a few bots that might interact with your PR. In particular, our continuous integration service will run tests and style checks on your new code. All PRs must be approved by the CI system before they will be merged, so watch out. They show up as either a red X or a green check mark in the PR.</p>"},{"location":"patching/#ready-to-merge","title":"Ready to Merge!","text":"<p>Once a pull request has gotten an <code>r+</code> (\"R-plus\", it's from Bugzilla) it's ready to merge in. At this point you can rebase and squash any feedback/fixup commits you want, but this isn\\'t required.</p> <p>If you don't have commit access, someone who does may do this for you, if they have time. Alternatively, if you have commit access, you can press GitHub's \"Merge pull request\" button, which does a similar process to below. This is the preferred way to merge PRs when there are no complications.</p> <pre><code>git checkout main\ngit reset --hard mozilla/main\ngit merge --no-ff my-feature-branch-123456\n# Make sure tests pass.\npython manage.py test\ngit push\n</code></pre> <p>You 're done! Congratulations, soon you will have code running on one of the biggest sites in the world!</p> <p>Before pushing to <code>mozilla/main</code>, I like to verify that the merge went fine in the logs. For the vast majority of merges, there should not be a merge commit.</p> <pre><code>git log --graph --decorate\ngit push mozilla main             # !!! Pushing code to the primary repo/branch!\n\n# Optionally, you can keep your Github main in sync.\ngit push origin main              # Not strictly necessary but kinda nice.\ngit push origin :my-feature-branch  # Nice to clean up.\n</code></pre> <p>This should automatically close the PR, as GitHub will notice the merge commit.</p> <p>Once the commit is on <code>mozilla/main</code>, copy the commit url to the bug.</p> <p>Once the commit has been deployed to stage and prod, set the bug to <code>RESOLVED FIXED</code>. This tells everyone that the fix is in production.</p>"},{"location":"questions/","title":"Ask A Question","text":"<p>This document explains what kinds of question states exist in Kitsune, how they are set and their implications.</p>"},{"location":"questions/#configuring-new-products","title":"Configuring new products","text":"<p>To configure a new product for AAQ you must edit <code>config.py</code> within the questions app.</p> <p>First, ensure the <code>Product</code> object exists for this product in the products app. If not create a new <code>Product</code>.</p> <p>Next, Add a new item to the <code>products</code> dictionary using something like:</p> <pre><code>('product-slug', {\n    'name': _lazy(u'Product Name'),\n    'subtitle': _lazy('A brief description'),\n    'extra_fields': [],\n    'tags': ['tag-slug'],\n    'product': 'product-slug',\n    'categories': SortedDict([\n        ('topic-slug', {\n            'name': _lazy(u'Topic name'),\n            'topic': 'topic-slug',\n            'tags': []\n        }),\n    ])\n}),\n</code></pre> <p><code>'product-slug'</code> should be the slug of the <code>Product</code> object for this product.</p>"},{"location":"questions/#question-states","title":"Question States","text":""},{"location":"questions/#default","title":"Default","text":"<p>This is the unmarked state of the thread.</p> <p>Implications:</p> <ul> <li>Users can reply</li> <li>Visible in regular SUMO searches (with at least one helpful reply)</li> <li>Visible to external searches</li> <li>Visible in the regular questions list</li> <li>Visible in the [related threads]{.title-ref} section</li> </ul>"},{"location":"questions/#locked","title":"Locked","text":"<p>This is the locked state of a thread. A thread can be locked in two ways:</p> <ul> <li>By manually locking it via the question UI</li> <li>Automatically after 180 days.</li> </ul> <p>Implications:</p> <ul> <li>Users can\\'t reply</li> <li>Moderators can unlock to reply</li> <li>If there is an answer, the locked thread is still shown by search     engines and our internal search.</li> <li>If there is no answer, the locked thread will not be shown by search     engines and our internal search.</li> </ul>"},{"location":"questions/#not-indexed","title":"Not indexed","text":"<p>Questions with no answers that are older than 30 days have a meta tag telling search engines not to show them.</p>"},{"location":"seo/","title":"SEO","text":"<p>This document covers notes and policies related to SEO.</p>"},{"location":"seo/#prefer-meta-tag-if-possible","title":"Prefer <code>meta</code> tag if possible","text":"<p>If an entire page should not be indexed, and/or none of its links followed, prefer to use the <code>&lt;meta name=\"robots\" ...&gt;</code> tag by specifying something like:</p> <pre><code>{% set meta = (('robots', 'noindex'),) %}\n</code></pre> <p>or:</p> <pre><code>{% set meta = (('robots', 'noindex, nofollow'),) %}\n</code></pre> <p>within the lowest-level Jinja2 templates of the inheritance chain that apply to only the desired pages.</p> <p>However, if you only want to discourage the crawling of specific links within a page, you\\'ll have to add <code>rel=\"nofollow\"</code> to each of those links within its template. For example:</p> <pre><code>&lt;a rel=\"nofollow\" href=\"...\"&gt;...&lt;/a&gt;\n</code></pre>"},{"location":"seo/#breadcrumbs","title":"Breadcrumbs","text":"<p>If one or more of the breadcrumb links for a page should not be crawled, you can add an extra string to those breadcrumb tuples to specify the proper attribute to use, for example:</p> <pre><code>{% set crumbs = [((profile_url(user), 'rel=\"nofollow\"'), user.username), (None, title)] %}\n</code></pre> <p>or:</p> <pre><code>{% set crumbs = [(document.get_absolute_url(), document.title), ((url('wiki.discuss.threads', document.slug), 'rel=\"ugc nofollow\"'), _('Discuss'))] %}\n</code></pre>"},{"location":"seo/#kb-forums","title":"KB Forums","text":"<p>KB forums are user-generated content about KB articles. They are not official content, and therefore not meant to be searchable. All links to KB forums should be marked with <code>rel=\"ugc nofollow\"</code>.</p>"},{"location":"seo/#user-links","title":"User Links","text":"<p>User-related pages are also not meant to be indexed (searchable), and links to them should not be crawled, so the base user template (<code>kitsune/users/jinja2/users/base.html</code>) contains:</p> <pre><code>{% set meta = (('robots', 'noindex'),) %}\n</code></pre> <p>and all user links on all pages should be marked with <code>rel=\"nofollow\"</code>.</p>"},{"location":"sla/","title":"Service Level Agreement","text":"<p>::: warning ::: title Warning :::</p> <p>This section of documentation may be outdated. :::</p> <p>This isn\\'t a zero-tolerance policy, but a series of policy points we work towards when making changes to the site.</p> <p>Measurements are based on what we can see in graphite which means it\\'s all server-side. Also, we use the upper_90 line since that tracks the more extreme side of performance.</p> <p>This SLA will probably change over time. Here it is now.</p> <ol> <li> <p>View performance</p> <p>upper_90 for server-side rendering of views for GET requests should be under 800ms.</p> </li> <li> <p>Search availability</p> <p>Search should work and return useful results.</p> <p>The implication here is that it\\'s not ok to be reindexing into an index that searches are against.</p> </li> <li> <p>Browser support</p> <p>See this page in the wiki:</p> <p>https://wiki.mozilla.org/Support/Browser_Support</p> </li> </ol>"},{"location":"svelte/","title":"Svelte","text":""},{"location":"svelte/#svelte","title":"Svelte","text":""},{"location":"svelte/#csssass","title":"CSS/SASS","text":"<p>Svelte supports writing CSS directly in a component within <code>&lt;style&gt;</code> tags, as well as writing compiled-to-CSS languages like SASS within <code>&lt;style lang=\"scss\"&gt;</code> tags.</p> <p>CSS written this way is automatically scoped to the component: read more in the Svelte docs.</p> <p>This SASS to CSS compilation is handled by <code>svelte-preprocess</code>, and the resulting CSS is handed to Wepback for further processing. Since Webpack isn't involved in SASS compilation within Svelte components, care must be taken in a few areas:</p> <ol> <li>Because Webpack isn't handling <code>@use</code> and <code>@import</code> resolution,    it's not possible to use its aliases to reference paths to other SASS files.    Instead paths relative to the Svelte component,    or full node module paths,    must be used.    This doesn't include paths not processed by the SASS compiler,    such as paths to images in <code>url()</code> functions,    as these are still handled by Webpack.    To illustrate:</li> </ol> <pre><code>@use \"@mozilla-protocol/core/protocol/css/includes/lib\" as p;\n@use \"../../kitsune/sumo/static/sumo/scss/config/typography-mixins\";\n// ^ here we must use a full or relative path, as svelte-preprocess is resolving this\n\ndiv {\n    background: url(\"protocol/img/icons/reader-mode.svg\");\n    // ^ here we can use a webpack alias, as webpack is resolving this\n    background-size: p.$spacing-md;\n    @include typography-mixins.text-display-sm;\n}\n</code></pre> <ol> <li> <p>As a knock-on effect of the above,    any partials used in both our main CSS bundle,    as well as a Svelte component (like the <code>typography-mixins</code> above)    must not use Webpack aliases in their own imports,    otherwise <code>svelte-preprocess</code> won't be able to resolve them.</p> </li> <li> <p>Partials should be careful to not accidentally include or import CSS blocks outside of mixin defintions.    This is because neither <code>svelte-preprocess</code> nor the Webpack <code>sass-loader</code> are able to chunk split <code>@import</code>s and <code>@use</code>s,    or even de-duplicate their use across Svelte components (due to the scoped nature of the CSS within).    Not doing this will lead to unnecessarily duplicated code.</p> </li> </ol>"},{"location":"svelte/#pre-rendering","title":"Pre-rendering","text":"<p>To pre-render Svelte components a two-step process is required.</p> <p>First the components must pass through the Svelte compiler, with the appropriate flags enabled to compile components for server-side rendering (SSR). Then those compiled components must be rendered into static HTML. We do both these steps in Webpack using the <code>webpack.pre-render.js</code> config file.</p> <p>In order to pre-render a route, add it to the config object passed to <code>svelte-pre-render-plugin</code> in <code>webpack.pre-render.js</code>, referencing the entrypoint containing the component you want to render:</p> <pre><code>entry: {\n    foobar: \"./svelte/SomeComponent\",\n    barfoo: \"./svelte/AnotherComponent\",\n},\nplugins: [\n    new SveltePreRenderPlugin({\n        \"foobar.js\": [\n            \"/route-1\",\n            \"/route-2\",\n            \"/route-2/subroute\",\n        ],\n        \"barfoo.js\": [\n            \"/route-3\",\n        ],\n    }),\n],\n</code></pre>"},{"location":"switching_devices/","title":"Switching devices","text":""},{"location":"switching_devices/#switching-devices-guidance","title":"Switching Devices Guidance","text":""},{"location":"switching_devices/#introduction","title":"Introduction","text":"<p>In Q2 of 2023, we introduced a mechanism to make it easier for users to migrate their Firefox data from old devices to new devices. A critical part of this project was a page hosted on Kitsune that walked a user through creating a Mozilla account, making sure syncing was set up, and then giving them the URL to a specially attributed download of Firefox that prioritizes signing in to a Mozilla account during onboarding.</p> <p>The page doesn't just offer instructions on how to do these things, but instead has an interactive \"wizard\" that takes the user through each step.</p> <p>This wizard is a UI component mostly powered by JavaScript in the front-end of Kitsune. The rest of this document details its behaviour and architecture.</p>"},{"location":"switching_devices/#usage","title":"Usage","text":"<p>The wizard requires two things to appear and function properly on a page:</p> <ol> <li>To have the page exist in <code>FIREFOX_SWITCHING_DEVICES_ARTICLES</code> in <code>settings.py</code> in order to get the right scripts loaded for it.</li> <li>To have the special tag <code>[[UI:device_migration_wizard]]</code> exist in the markup once (and only once) on the page. At publish-time, this tag is replaced with the markup defined in <code>hook_device_migration_wizard.html</code>.</li> </ol>"},{"location":"switching_devices/#architecture","title":"Architecture","text":"<p>The mechanism for the wizard is broken into two subcomponents - the <code>SwitchingDevicesWizardManager</code> JavaScript object and the <code>&lt;form-wizard&gt;</code> custom element.</p>"},{"location":"switching_devices/#form-wizard","title":"<code>&lt;form-wizard&gt;</code>","text":"<p>The <code>&lt;form-wizard&gt;</code> is a customElement that knows how to receive communications from <code>SwitchingDevicesWizardManager</code> that describe a step to be on (and what state that step should be in).</p> <p>Please see the <code>&lt;form-wizard&gt;</code> source for the documentation the public mechanisms that are exposed to the <code>SwitchingDevicesWizardManager</code>.</p> <p>The <code>form-wizard.js</code> script also exposes a <code>BaseFormStep</code> class which needs to be subclassed for each step that is to be represented in the wizard.</p>"},{"location":"switching_devices/#baseformstep","title":"<code>BaseFormStep</code>","text":"<p>A step shown in the <code>&lt;form-wizard&gt;</code> is represented by a subclass of <code>BaseFormStep</code> as a customElement, and then placed within the <code>&lt;form-wizard&gt;</code> element as direct descendants in the markup.</p> <p>Each step must implement the <code>template</code> getter, in order to define the HTML markup for the step. It can also optionally override the <code>render</code> method in the event that it can be in several states based on the information from <code>SwitchingDevicesWizardManager</code>.</p> <p>See the implementations of <code>SignInStep</code>, <code>ConfigureStep</code> and <code>SetupDeviceStep</code> for examples.</p>"},{"location":"switching_devices/#switchingdeviceswizardmanager","title":"<code>SwitchingDevicesWizardManager</code>","text":"<p>The <code>SwitchingDevicesWizardManager</code> is a singleton object whose sole job is to process incoming events or callbacks and reconcile those with the existing internal state to generate a new state. That state is then passed along to the <code>&lt;form-wizard&gt;</code> to be seen by the user. The <code>SwitchingDevicesWizardManager</code> is effectively a very simple state machine where each state of the machine maps to one of the steps in the <code>&lt;form-wizard&gt;</code>.</p> <p>This is a diagram of the state machine logic:</p> <p></p> <p>The <code>&lt;form-wizard&gt;</code> is expected to exist in the DOM by the time that the <code>SwitchingDevicesWizardManager</code> initializes. Page script will be expected to constructed the <code>SwitchingDevicesWizardManager</code> with a reference to the <code>&lt;form-wizard&gt;</code>.</p> <p>The <code>SwitchingDevicesWizardManager</code> is also responsible for performing any special network or <code>UITour</code> requests to get additional data to help compute which step the user is on. Once it has computed the step, it calls the <code>setStep</code> method on the <code>&lt;form-wizard&gt;</code> to present that step to the user.</p>"},{"location":"tests/","title":"All about testing","text":"<p>Warning</p> <p>This section of documentation may be outdated.</p> <p>Kitsune has a fairly comprehensive Python test suite. Changes should not break tests---only change a test if there is a good reason to change the expected behavior---and new code should come with tests.</p>"},{"location":"tests/#running-the-test-suite","title":"Running the Test Suite","text":"<p>If you followed the steps in <code>the installation docs &lt;hacking_howto&gt;</code>{.interpreted-text role=\"any\"}, then you should be all set setup-wise.</p> <p>To run the tests, you need to do:</p> <pre><code>./manage.py test\n</code></pre> <p>That doesn't provide the most sensible defaults for running the tests. Here is a good command to alias to something short:</p> <pre><code>./manage.py test -s --noinput --logging-clear-handlers\n</code></pre> <p>The <code>-s</code> flag is important if you want to be able to drop into PDB from within tests.</p> <p>Some other helpful flags are:</p> <code>-x</code>: <p>Fast fail. Exit immediately on failure. No need to run the whole test suite if you already know something is broken.</p> <code>--pdb</code>: <p>Drop into PDB on an uncaught exception. (These show up as <code>E</code> or errors in the test results, not <code>F</code> or failures.)</p> <code>--pdb-fail</code>: <p>Drop into PDB on a test failure. This usually drops you right at the assertion.</p> <code>--no-skip</code>: <p>All SkipTests show up as errors. This is handy when things shouldn't be skipping silently with reckless abandon.</p>"},{"location":"tests/#running-a-subset-of-tests","title":"Running a Subset of Tests","text":"<p>You can run part of the test suite by specifying the apps you want to run, like:</p> <pre><code>./manage.py test kitsune/wiki kitsune/search kitsune/kbforums\n</code></pre> <p>You can also specify modules:</p> <pre><code>./manage.py test kitsune.wiki.tests.test_views\n</code></pre> <p>You can specify specific tests:</p> <pre><code>./manage.py test kitsune.wiki.tests.test_views:VersionGroupTests.test_version_groups\n</code></pre> <p>See the output of <code>./manage.py test --help</code> for more arguments.</p>"},{"location":"tests/#running-tests-without-collecting-static-files","title":"Running tests without collecting static files","text":"<p>By default the test runner will run <code>collectstatic</code> to ensure that all the required assets have been collected to the static folder. If you do not want this default behavior you can run:</p> <pre><code>REUSE_STATIC=1 ./manage.py test\n</code></pre>"},{"location":"tests/#the-test-database","title":"The Test Database","text":"<p>The test suite will create a new database named <code>test_%s</code> where <code>%s</code> is whatever value you have for <code>settings.DATABASES['default']['NAME']</code>.</p> <p>Make sure the user has <code>ALL</code> on the test database as well. This is covered in the installation chapter.</p> <p>When the schema changes, you may need to drop the test database. You can also run the test suite with <code>FORCE_DB</code> once to cause Django to drop and recreate it:</p> <pre><code>FORCE_DB=1 ./manage.py test -s --noinput --logging-clear-handlers\n</code></pre>"},{"location":"tests/#writing-new-tests","title":"Writing New Tests","text":"<p>Code should be written so it can be tested, and then there should be tests for it.</p> <p>When adding code to an app, tests should be added in that app that cover the new functionality. All apps have a <code>tests</code> module where tests should go. They will be discovered automatically by the test runner as long as the look like a test.</p> <ul> <li>We use \"modelmakers\" instead of fixtures. Models should have     modelmakers defined in the tests module of the Django app. For     example, <code>forums.tests.document</code> is the modelmaker for     <code>forums.Models.Document</code> class.</li> </ul>"},{"location":"tests/#changing-tests","title":"Changing Tests","text":"<p>Unless the current behavior, and thus the test that verifies that behavior is correct, is demonstrably wrong, don't change tests. Tests may be refactored as long as its clear that the result is the same.</p>"},{"location":"tests/#removing-tests","title":"Removing Tests","text":"<p>On those rare, wonderful occasions when we get to remove code, we should remove the tests for it, as well.</p> <p>If we liberate some functionality into a new package, the tests for that functionality should move to that package, too.</p>"},{"location":"tests/#javascript-tests","title":"JavaScript Tests","text":"<p>Frontend JavaScript is currently tested with Mocha.</p>"},{"location":"tests/#running-javascript-tests","title":"Running JavaScript Tests","text":"<p>To run tests, make sure you have have the NPM dependencies installed, and then run:</p> <pre><code>$ npm run webpack:test\n</code></pre>"},{"location":"tests/#writing-javascript-tests","title":"Writing JavaScript Tests","text":"<p>Mocha tests are discovered using the pattern <code>kitsune/*/static/*/js/tests/**/*.js</code>. That means that any app can have a [tests]{.title-ref} directory in its JavaScript directory, and the files in there will all be considered test files. Files that don't define tests won't cause issues, so it is safe to put testing utilities in these directories as well.</p> <p>Here are a few tips for writing tests:</p> <ul> <li>Any HTML required for your test should be added by the tests or a     <code>beforeEach</code> function in that test suite. React is useful for this.</li> <li>You can use [sinon]{.title-ref} to mock out parts of libraries or     functions under test. This is useful for testing AJAX.</li> <li>The tests run in a Node.js environment. A browser environment can be     simulated using <code>jsdom</code>.</li> </ul>"},{"location":"users/","title":"Users","text":"<p>Kitsune uses Mozilla accounts for authentication: https://support.mozilla.org/kb/firefox-accounts-mozilla-support-faq</p>"},{"location":"zendesk/","title":"Zendesk","text":""},{"location":"zendesk/#zendesk-integration","title":"Zendesk integration","text":""},{"location":"zendesk/#using-requests-to-query-the-api","title":"Using <code>requests</code> to query the API","text":"<p>During development being able to query the API manually to fetch details about field IDs, user statuses, and so on is very useful.</p> <p>To do so use a snippet of code like the following in <code>./manage.py shell_plus</code>:</p> <pre><code>import requests\nbase = f\"https://{settings.ZENDESK_SUBDOMAIN}.zendesk.com/api/v2/\"\nauth = requests.auth.HTTPBasicAuth(settings.ZENDESK_USER_EMAIL+\"/token\", settings.ZENDESK_API_TOKEN)\n\nrequests.get(base+\"foobar\", auth=auth).json()\n\nrequests.post(base+\"barfoo\", auth=auth, json={}).json()\n</code></pre>"},{"location":"architecture/decisions/0001-record-architecture-decisions/","title":"Record","text":""},{"location":"architecture/decisions/0001-record-architecture-decisions/#1-record-architecture-decisions","title":"1 - Record architecture decisions","text":"<p>Date: 2019-01-10</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#status","title":"Status","text":"<p>Accepted</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#context","title":"Context","text":"<p>We need to record the architectural decisions made on this project.</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#decision","title":"Decision","text":"<p>We will use Architecture Decision Records, as described by Michael Nygard.</p>"},{"location":"architecture/decisions/0001-record-architecture-decisions/#consequences","title":"Consequences","text":"<p>See Michael Nygard's article, linked above. For a lightweight ADR toolset, see Nat Pryce's adr-tools.</p>"},{"location":"architecture/decisions/0002-es-l10n-content/","title":"Search - L10N content","text":""},{"location":"architecture/decisions/0002-es-l10n-content/#2-storing-localized-content-in-search","title":"2 - Storing localized content in Search","text":"<p>Date: 2020-10-27</p>"},{"location":"architecture/decisions/0002-es-l10n-content/#status","title":"Status","text":"<p>Pending</p>"},{"location":"architecture/decisions/0002-es-l10n-content/#context","title":"Context","text":"<p>Kitsune supports many locales, and has content which we want to be searchable in those locales.</p> <p>Elasticsearch has support for many language-specific analyzers: https://www.elastic.co/guide/en/elasticsearch/reference/7.9/analysis-lang-analyzer.html</p> <p>Search v1 used per-document analyzers, that is to say, within the same index:</p> <pre><code>doc_1: { \"content\": \"Hello world\" }\ndoc_2: { \"content\": \"Hallo Welt\" }\n</code></pre> <p><code>doc_1.content</code> could be analyzed using an english analyzer, and <code>doc_2.content</code> could be analyzed using a german analyzer.</p> <p>Well before version 7 ES removed this feature, and now all fields of the same name across an index must be analyzed the same, so we must take a different approach with the current Search implementation.</p> <p>We can either place separate locales in their own index, and set up locale-specific analyzers for the same field name across indices. Or we can keep separate locales within the same index, and define unique field names for each field which needs to be analyzed under a specific locale.</p>"},{"location":"architecture/decisions/0002-es-l10n-content/#decision","title":"Decision","text":"<p>Heavily influenced by: https://www.elastic.co/blog/multilingual-search-using-language-identification-in-elasticsearch</p> <p>We will store all documents within the same index and use an Object field for fields which need to use locale-specific analyzers.</p> <p>We will call this field <code>SumoLocaleAwareTextField</code> and will have a key for each locale, with the appropriate analyzer defined on that key, such that:</p> <pre><code>doc_1: { \"content\": { \"en-US\": \"Hello world\" }}\ndoc_2: { \"content\": { \"de\": \"Hallo Welt\" }}\n</code></pre> <p><code>doc_1.content.en-US</code> is analyzed using an english analyzer, and <code>doc_2.content.de</code> is analyzed using a german analyzer.</p>"},{"location":"architecture/decisions/0002-es-l10n-content/#consequences","title":"Consequences","text":"<p>We won't need to manage many indeces of wildly different sizes, as we would if we used one index per locale.</p> <p>Documents within a specific locale can be searched for by searching on the <code>field.locale-name</code> field, for instance <code>content.en-US</code>.</p> <p>Searching across all locales can be performed with a wildcard (like <code>content.*</code>).</p>"},{"location":"architecture/decisions/0003-es-aaq-documents/","title":"Search - AAQ content","text":""},{"location":"architecture/decisions/0003-es-aaq-documents/#3-aaq-structure-in-search","title":"3 - AAQ structure in Search","text":"<p>Date: 2020-10-27</p>"},{"location":"architecture/decisions/0003-es-aaq-documents/#status","title":"Status","text":"<p>Pending</p>"},{"location":"architecture/decisions/0003-es-aaq-documents/#context","title":"Context","text":"<p>As we are re-implementing our search in ElasticSearch v7, we must re-implement Ask a Question (AAQ) search.</p> <p>There is one primary use-case for storing AAQ documents in ES which Search v1 supports, which we must continue to be able to do in the redesigned Search: searching for an AAQ thread as a unit.</p> <p>There are other secondary use-cases which we may want to support when storing AAQ documents in ES. A non-exhaustive list of these are:</p> <ul> <li>Searching within AAQ threads</li> <li>Searching within questions and their solutions</li> <li>Aggregating answers to create contribution data</li> </ul> <p>We also want search to be fast, so should model our data to avoid nested fields and parent-child relationships, and use de-normalization wherever possible: https://www.elastic.co/guide/en/elasticsearch/reference/7.9/tune-for-search-speed.html#_document_modeling</p>"},{"location":"architecture/decisions/0003-es-aaq-documents/#decision","title":"Decision","text":"<p>We will model our data in ES based on what makes most sense for our expected use-cases, and what will make those fast and efficient, rather than feeling like we must have a 1:1 copy of our data structure in our database.</p> <p>In this vein, we will use a structure of two document \"types\" within one index, <code>QuestionDocument</code> and <code>AnswerDocument</code>, where a <code>QuestionDocument</code> will exist for each <code>Question</code> which exists in the database, and an <code>AnswerDocument</code> will exist for each <code>Answer</code> which exists in the database.</p> <p><code>AnswerDocument</code> will be a subclass of <code>QuestionDocument</code> so will inherit all of its fields, and we will set the value of those fields to the value of the <code>Question</code> associated with its <code>Answer</code>.</p> <p>For instance, if in database:</p> <pre><code>answer.created =&gt; 2020-10-27\nanswer.question.created =&gt; 2020-11-01\n</code></pre> <p>in elastic:</p> <pre><code>answer_document.created =&gt; 2020-10-27\nanswer_document.question_created =&gt; 2020-11-01\n</code></pre> <p><code>QuestionDocument</code> will also have an <code>answer_content</code> field, which contains the content of all a Question's Answers. We will set this to null in the <code>AnswerDocument</code>.</p>"},{"location":"architecture/decisions/0003-es-aaq-documents/#consequences","title":"Consequences","text":"<p><code>QuestionDocument</code>s can be distinguished from <code>AnswerDocument</code>s by whether the <code>created</code> value is null or not.</p> <p>This structure gives us great flexibility over the type of searches and aggregations we can do:</p> <ul> <li> <p>AAQ threads can be searched over as a unit by searching over the <code>question_content</code> and <code>answer_content</code> fields on a <code>QuestionDocument</code>.     Collapsing or aggregations aren't required to ensure that threads only appear once,     which wouldn't be the case if we didn't have an <code>answer_content</code> field.</p> </li> <li> <p>Searches within AAQ threads are possible by searching over the <code>question_content</code> fields on a <code>QuestionDocument</code>,     and the <code>content</code> fields on an <code>AnswerDocument</code>.</p> </li> <li> <p>Searches can be limited to Question content and the content of Answers which are solutions by filtering by <code>is_solved: True</code>,     and searching over <code>question_content</code> and <code>content</code> fields.</p> </li> <li> <p>Aggregations on Answers,     such as gathering contribution metrics,     can be performed by aggregating <code>AnswerDocument</code>s.</p> </li> </ul> <p>There may be some Question data indexed in <code>AnswerDocument</code>s which we never use.</p>"},{"location":"architecture/decisions/0004-type-checking/","title":"Type Checking","text":""},{"location":"architecture/decisions/0004-type-checking/#4-type-hints-and-checking","title":"4 - Type Hints and Checking","text":"<p>Date: 2023-02-15</p>"},{"location":"architecture/decisions/0004-type-checking/#status","title":"Status","text":"<p>Pending</p>"},{"location":"architecture/decisions/0004-type-checking/#context","title":"Context","text":"<p>With support for type hints and static type-checking tools solidly entrenched in the Python eco-system, we'd like to take advantage of both within Kitsune. The goal is to support gradual typing, to support the addition of type-hints only where they're helpful, where their addition adds more value than their burden.</p> <p>Type hints can be helpful to quickly understand the types of values expected by functions and methods, as well as the types of their results, easing the burden of using those functions/methods for the first time. It encourages modularity, since one doesn't have to dig into the details of the underlying code to discover what's expected. Once in place, they also enable the use of static type-checking tools, which can flag basic interface errors, for example, when you're passing a <code>str</code> into a function that expects an <code>int</code>.</p> <p>Type hints can sometimes be an undue burden as well. In some cases determining the correct type can be difficult, time-consuming, and the outcome unintuitive. In those cases, it's probably better to skip them.</p> <p>In the end, it's important to remember that type hints and static type-checking are never a substitute for testing. Writing good tests for your code is essential whether you add type hints or not.</p>"},{"location":"architecture/decisions/0004-type-checking/#decision","title":"Decision","text":"<p>We recommend that all pull requests that modify/create Python functions and/or methods, add a type hint for each of the function/method arguments as well as the result. There's a judgement call here though. If it's an \"undue burden\", skip it. If not, do it.</p> <p>Also, we will run a static type-checking tool, either prior to commits, or during CI, or both.</p>"},{"location":"architecture/decisions/0004-type-checking/#consequences","title":"Consequences","text":"<p>There are two primary consequences.</p> <ul> <li> <p>An easier, less error-prone coding experience when working with unfamiliar Python   functions/methods.</p> </li> <li> <p>We reap the benefits of using a static type-checking tool. For example, the   detection, prior to run time, of interface errors, where the types passed into   functions/methods or the results returned are not what's expected.</p> </li> </ul> <p>There is the potential for this to have a negative consequence as well. It could slow us down. It could cost more than its worth. So, it's important to keep in mind the tradeoff. Type hints should only be added where they're helpful.</p>"}]}